{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FNLP_Word2Vec_Pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "gZJOn8YNh1qd",
        "ESJnr7KeBvHx"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CamilaKim/Study/blob/master/FNLP_Word2Vec_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Zisceuy__V-U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **FNLP_Word2Vec_Pytorch**\n"
      ]
    },
    {
      "metadata": {
        "id": "gZJOn8YNh1qd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Gensim"
      ]
    },
    {
      "metadata": {
        "id": "0w7UgZldi6Dn",
        "colab_type": "code",
        "outputId": "fedb0d89-5f13-4f4c-b891-7f1bb67d770c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.128)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.128 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.128)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.0)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.128->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.128->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jN7pX8EEELGS",
        "colab_type": "code",
        "outputId": "98c24fff-4b16-4933-fa57-113fa337bf14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#https://towardsdatascience.com/word-embedding-with-word2vec-and-fasttext-a209c1d3e12c\n",
        "import numpy as np\n",
        "import os\n",
        "from random import shuffle\n",
        "import re\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import lxml.etree\n",
        "#download the data\n",
        "urllib.request.urlretrieve(\"https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip\", filename=\"ted_en-20160408.zip\")\n",
        "# extract subtitle\n",
        "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
        "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
        "input_text = '\\n'.join(doc.xpath('//content/text()'))\n",
        "# remove parenthesis \n",
        "input_text_noparens = re.sub(r'\\([^)]*\\)', '', input_text)\n",
        "# store as list of sentences\n",
        "sentences_strings_ted = []\n",
        "for line in input_text_noparens.split('\\n'):\n",
        "    m = re.match(r'^(?:(?P<precolon>[^:]{,20}):)?(?P<postcolon>.*)$', line)\n",
        "    sentences_strings_ted.extend(sent for sent in m.groupdict()['postcolon'].split('.') if sent)\n",
        "# store as list of lists of words\n",
        "sentences_ted = []\n",
        "for sent_str in sentences_strings_ted:\n",
        "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", sent_str.lower()).split()    \n",
        "    sentences_ted.append(tokens)\n",
        "from gensim.models import Word2Vec\n",
        "model_ted = Word2Vec(sentences=sentences_ted, size=100, window=5, min_count=5, workers=4, sg=0)\n",
        "print(model_ted)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=21444, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vHvvH4RAE9N2",
        "colab_type": "code",
        "outputId": "bf128e2b-f500-44b8-bb40-164f4ee46089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "print(input_text[:300])\n",
        "print(input_text_noparens.split('\\n')[:10])\n",
        "print(sentences_strings_ted[:10])\n",
        "print(sentences_ted[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Here are two reasons companies fail: they only do more of the same, or they only do what's new.\n",
            "To me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation. Both are necessary, but it can be too much of a good thing.\n",
            "Consider Facit\n",
            "[\"Here are two reasons companies fail: they only do more of the same, or they only do what's new.\", 'To me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation. Both are necessary, but it can be too much of a good thing.', \"Consider Facit. I'm actually old enough to remember them. Facit was a fantastic company. They were born deep in the Swedish forest, and they made the best mechanical calculators in the world. Everybody used them. And what did Facit do when the electronic calculator came along? They continued doing exactly the same. In six months, they went from maximum revenue ... and they were gone. Gone.\", 'To me, the irony about the Facit story is hearing about the Facit engineers, who had bought cheap, small electronic calculators in Japan that they used to double-check their calculators.', '', 'Facit did too much exploitation. But exploration can go wild, too.', 'A few years back, I worked closely alongside a European biotech company. Let\\'s call them OncoSearch. The company was brilliant. They had applications that promised to diagnose, even cure, certain forms of blood cancer. Every day was about creating something new. They were extremely innovative, and the mantra was, \"When we only get it right,\" or even, \"We want it perfect.\" The sad thing is, before they became perfect -- even good enough -- they became obsolete. OncoSearch did too much exploration.', 'I first heard about exploration and exploitation about 15 years ago, when I worked as a visiting scholar at Stanford University. The founder of the idea is Jim March. And to me the power of the idea is its practicality.', \"Exploration. Exploration is about coming up with what's new. It's about search, it's about discovery, it's about new products, it's about new innovations. It's about changing our frontiers. Our heroes are people who have done exploration: Madame Curie, Picasso, Neil Armstrong, Sir Edmund Hillary, etc. I come from Norway; all our heroes are explorers, and they deserve to be. We all know that exploration is risky. We don't know the answers, we don't know if we're going to find them, and we know that the risks are high.\", \"Exploitation is the opposite. Exploitation is taking the knowledge we have and making good, better. Exploitation is about making our trains run on time. It's about making good products faster and cheaper. Exploitation is not risky -- in the short term. But if we only exploit, it's very risky in the long term. And I think we all have memories of the famous pop groups who keep singing the same songs again and again, until they become obsolete or even pathetic. That's the risk of exploitation.\"]\n",
            "[\"Here are two reasons companies fail: they only do more of the same, or they only do what's new\", 'To me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation', ' Both are necessary, but it can be too much of a good thing', 'Consider Facit', \" I'm actually old enough to remember them\", ' Facit was a fantastic company', ' They were born deep in the Swedish forest, and they made the best mechanical calculators in the world', ' Everybody used them', ' And what did Facit do when the electronic calculator came along? They continued doing exactly the same', ' In six months, they went from maximum revenue ']\n",
            "[['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new'], ['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation'], ['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing'], ['consider', 'facit'], ['i', 'm', 'actually', 'old', 'enough', 'to', 'remember', 'them'], ['facit', 'was', 'a', 'fantastic', 'company'], ['they', 'were', 'born', 'deep', 'in', 'the', 'swedish', 'forest', 'and', 'they', 'made', 'the', 'best', 'mechanical', 'calculators', 'in', 'the', 'world'], ['everybody', 'used', 'them'], ['and', 'what', 'did', 'facit', 'do', 'when', 'the', 'electronic', 'calculator', 'came', 'along', 'they', 'continued', 'doing', 'exactly', 'the', 'same'], ['in', 'six', 'months', 'they', 'went', 'from', 'maximum', 'revenue']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1sCpIhrKwakZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***model_ted = Word2Vec(sentences=sentences_ted, size=100, window=5, min_count=5, workers=4, sg=0)***\n",
        "\n",
        "\n",
        "The parameters:\n",
        "\n",
        "> min_count = int - Ignores all words with total absolute frequency lower than this - (2, 100)\n",
        "\n",
        "> window = int - The maximum distance between the current and predicted word within a sentence. E.g. window words on the left and window words on the left of our target - (2, 10)\n",
        "\n",
        "> size = int - Dimensionality of the feature vectors. - (50, 300)\n",
        "\n",
        "> sample = float - The threshold for configuring which higher-frequency words are randomly downsampled. Highly influencial. - (0, 1e-5)\n",
        "\n",
        "> alpha = float - The initial learning rate - (0.01, 0.05)\n",
        "\n",
        "> min_alpha = float - Learning rate will linearly drop to min_alpha as training progresses. To set it: alpha - (min_alpha * epochs) ~ 0.00\n",
        "\n",
        "> negative = int - If > 0, negative sampling will be used, the int for negative specifies how many \"noise words\" should be drown. If set to 0, no negative sampling is used. - (5, 20)\n",
        "\n",
        "> workers = int - Use these many worker threads to train the model (=faster training with multicore machines)\n",
        "\n",
        "> sg=0 -> CBOW,  sg=1 -> Skip-gram\n",
        "\n",
        "[gensim-word2vec-tutorial](https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial)"
      ]
    },
    {
      "metadata": {
        "id": "sOfR8zWGf6YO",
        "colab_type": "code",
        "outputId": "2eba3104-5ff2-44d1-a1cd-6f29ab61d8d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "cell_type": "code",
      "source": [
        "model_ted.wv.most_similar(\"birds\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('animals', 0.8253463506698608),\n",
              " ('trees', 0.8173699378967285),\n",
              " ('rocks', 0.7838062047958374),\n",
              " ('bears', 0.7815128564834595),\n",
              " ('plants', 0.7564704418182373),\n",
              " ('corals', 0.7550895810127258),\n",
              " ('elephants', 0.7469815015792847),\n",
              " ('bees', 0.7403792142868042),\n",
              " ('landscapes', 0.7335201501846313),\n",
              " ('forests', 0.732998251914978)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "metadata": {
        "id": "r5NpxFjoxjWZ",
        "colab_type": "code",
        "outputId": "cd30a270-5ffe-4c86-cddd-0ee777c2501e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "model_ted.wv.similarity('rainy', 'sunny')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.79946184"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "metadata": {
        "id": "QVLVFP0Ux9c_",
        "colab_type": "code",
        "outputId": "5ef9a7fc-7ed7-425a-ecac-d8a8cf4bf868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "model_ted.wv.doesnt_match(['pollution', 'disaster', 'apple'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'apple'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "metadata": {
        "id": "wEUyzkudBhnf",
        "colab_type": "code",
        "outputId": "5447c1c4-c92f-4c0d-e31f-045b257b5d3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        " \n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "\n",
        "def tsnescatterplot(model, word, list_names):\n",
        "    print(model,word,list_names)\n",
        "    \"\"\" Plot in seaborn the results from the t-SNE dimensionality reduction algorithm of the vectors of a query word,\n",
        "    its list of most similar words, and a list of words.\n",
        "    \"\"\"\n",
        "    arrays = np.empty((0, 100), dtype='f')\n",
        "    word_labels = [word]\n",
        "    color_list  = ['red']\n",
        "\n",
        "    # adds the vector of the query word\n",
        "    arrays = np.append(arrays, model.wv.__getitem__([word]), axis=0)\n",
        "    \n",
        "    # gets list of most similar words\n",
        "    close_words = model.wv.most_similar([word])\n",
        "    \n",
        "    # adds the vector for each of the closest words to the array\n",
        "    for wrd_score in close_words:\n",
        "        wrd_vector = model.wv.__getitem__([wrd_score[0]])\n",
        "        word_labels.append(wrd_score[0])\n",
        "        color_list.append('blue')\n",
        "        arrays = np.append(arrays, wrd_vector, axis=0)\n",
        "    \n",
        "    # adds the vector for each of the words from list_names to the array\n",
        "    for wrd in list_names:\n",
        "        wrd_vector = model.wv.__getitem__([wrd])\n",
        "        word_labels.append(wrd)\n",
        "        color_list.append('green')\n",
        "        arrays = np.append(arrays, wrd_vector, axis=0)\n",
        "        \n",
        "     # Reduces the dimensionality from 300 to 50 dimensions with PCA\n",
        "#     reduc = PCA(n_components=50).fit_transform(arrays)\n",
        "    reduc = PCA(n_components=1).fit_transform(arrays)\n",
        "    \n",
        "    # Finds t-SNE coordinates for 2 dimensions\n",
        "    np.set_printoptions(suppress=True)\n",
        "    \n",
        "    Y = TSNE(n_components=2, random_state=0, perplexity=15).fit_transform(reduc)\n",
        "    \n",
        "    # Sets everything up to plot\n",
        "    df = pd.DataFrame({'x': [x for x in Y[:, 0]],\n",
        "                       'y': [y for y in Y[:, 1]],\n",
        "                       'words': word_labels,\n",
        "                       'color': color_list})\n",
        "    \n",
        "    fig, _ = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)\n",
        "    \n",
        "    # Basic plot\n",
        "    p1 = sns.regplot(data=df,\n",
        "                     x=\"x\",\n",
        "                     y=\"y\",\n",
        "                     fit_reg=False,\n",
        "                     marker=\"o\",\n",
        "                     scatter_kws={'s': 40,\n",
        "                                  'facecolors': df['color']\n",
        "                                 }\n",
        "                    )\n",
        "    \n",
        "    # Adds annotations one by one with a loop\n",
        "    for line in range(0, df.shape[0]):\n",
        "         p1.text(df[\"x\"][line],\n",
        "                 df['y'][line],\n",
        "                 '  ' + df[\"words\"][line].title(),\n",
        "                 horizontalalignment='left',\n",
        "                 verticalalignment='bottom', size='medium',\n",
        "                 color=df['color'][line],\n",
        "                 weight='normal'\n",
        "                ).set_size(15)\n",
        "\n",
        "    \n",
        "    plt.xlim(Y[:, 0].min()-50, Y[:, 0].max()+50)\n",
        "    plt.ylim(Y[:, 1].min()-50, Y[:, 1].max()+50)\n",
        "            \n",
        "    plt.title('t-SNE visualization for {}'.format(word.title()))\n",
        "tsnescatterplot(model_ted, 'head',['hand','leg'])    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=21444, size=100, alpha=0.025) head ['hand', 'leg']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAIlCAYAAAAZusgfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmAKhBQAAmAKhBQAAmAKhBQAAmML/A29fPORxEBBPAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 648x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "nojuTARqCEEn",
        "colab_type": "code",
        "outputId": "022f3cc0-517b-4f81-9b17-628263aa5b7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "cell_type": "code",
      "source": [
        "tsnescatterplot(model_ted, 'family', [i[0] for i in model_ted.wv.most_similar(negative=[\"family\"])])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=21444, size=100, alpha=0.025) family ['quantum', 'raw', 'cheapest', 'generic', 'arcane', 'vertical', 'maps', 'profiling', 'neat', 'unexplored']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAIlCAYAAADL6sJHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRMRw/h8IN6rYppqG3QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 648x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "7sJNQB3-IRtC",
        "colab_type": "code",
        "outputId": "6fdf65b1-d8dc-498f-a517-a91a3df7d93d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "cell_type": "code",
      "source": [
        "tsnescatterplot(model_ted, \"head\", [t[0] for t in model_ted.wv.most_similar(positive=[\"head\"], topn=20)][10:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=21444, size=100, alpha=0.025) head ['knee', 'seat', 'chair', 'finger', 'hair', 'bed', 'teeth', 'bedroom', 'shoulders', 'door']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAIlCAYAAAAZusgfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEhRaRERExBIUWkRERMQS/j+LmiFYwQq9DQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 648x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "eqOTJhgpiaEO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def openlang(filename):\n",
        "  f = open(filename+'.txt', 'r')\n",
        "  sentences=[]\n",
        "  line = f.readlines()\n",
        "  for l in line:\n",
        "    sentences.append(l)  \n",
        "  f.close()\n",
        "  return sentences\n",
        "doc2=openlang('koenTed')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l8ikf70JmWDq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from random import shuffle\n",
        "import re\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import lxml.etree\n",
        "#download the data\n",
        "input_text2 = ' '.join(doc2)\n",
        "# remove parenthesis \n",
        "input_text2_noparens = re.sub(r'\\([^)]*\\)', '', input_text2)\n",
        "# store as list of sentences\n",
        "sentences_ted = []\n",
        "for sent_str in input_text2_noparens.split('\\n'):\n",
        "    tokens = re.sub(r\"[^a-z0-9ㄱ-힣]+\", \" \", sent_str.lower()).split()    \n",
        "    sentences_ted.append(tokens)\n",
        "from gensim.models import Word2Vec\n",
        "model_ted = Word2Vec(sentences=sentences_ted, size=100, window=5, min_count=5, workers=4, sg=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5V1JiRtVsA28",
        "colab_type": "code",
        "outputId": "e11a4e1f-6cd8-40be-e7e2-fe780d13b25a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "print(input_text2_noparens.split('\\n')[:10])\n",
        "print(sentences_ted[:100])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['당신이 잡은 물고기는 얼마나 컸습니까? ', ' 이만큼 큽니까? ', ' 이만큼이요? ', ' 아니면 이만큼? ', ' 사진 증거가 없으면 ', ' 당신이 엄청나게 큰 물고기를  잡았다는 걸 증명할 길이 없죠. ', ' 낚시의 역사가 시작된 이래로 항상 그랬습니다. ', ' 사실, 수백년 전에, ', ' 사진으로 그 순간을 포착할 수 없던 그 옛날에, ', ' 일본 어부들은 자신들만의 방법을 발명하여 ']\n",
            "[['당신이', '잡은', '물고기는', '얼마나', '컸습니까'], ['이만큼', '큽니까'], ['이만큼이요'], ['아니면', '이만큼'], ['사진', '증거가', '없으면'], ['당신이', '엄청나게', '큰', '물고기를', '잡았다는', '걸', '증명할', '길이', '없죠'], ['낚시의', '역사가', '시작된', '이래로', '항상', '그랬습니다'], ['사실', '수백년', '전에'], ['사진으로', '그', '순간을', '포착할', '수', '없던', '그', '옛날에'], ['일본', '어부들은', '자신들만의', '방법을', '발명하여'], ['대어를', '낚은', '것을', '기록했습니다'], ['일본인들은', '그', '방법을', '교타쿠', '라고', '부릅니다'], ['교타쿠는', '물고기를', '그리는', '고대', '미술인데요'], ['일본에서', '유래됐습니다'], ['현대의', '카메라가', '발명되기', '전에'], ['대어를', '낚는', '순간을', '기록하기', '위한', '방법이었죠'], ['교', '는', '물고기를', '뜻하고'], ['타쿠', '는', '인상을', '의미합니다'], ['교타쿠가', '어떻게', '시작됐는지에', '대해서는'], ['여러가지', '설이', '있습니다'], ['하지만', '기본적으로는', '어부들이'], ['자신이', '잡은', '물고기의', '종과', '크기를', '기록할', '수단이', '필요해서'], ['100여년', '전부터', '사용했습니다'], ['어부들은', '종이와', '잉크', '붓을', '가지고'], ['바다로', '나갔습니다'], ['그들은', '바다에서의', '엄청난', '모험', '이야기를', '들려주었습니다'], ['일본인들은', '특정한', '물고기를', '숭배했기', '때문에'], ['이', '물고기들의', '탁본을', '뜬', '후에'], ['다시', '바다로', '놓아주었습니다'], ['탁본을', '뜨기', '위해서는'], ['물고기에다', '무독성의', '먹물을', '바른', '후에'], ['고급', '화선지에', '찍습니다'], ['그런', '후에', '물고기를', '다시', '놓아', '주거나'], ['깨끗이', '씻어서', '시장에', '내다', '팔았습니다'], ['초기의', '교타쿠는', '이', '그림처럼', '기록만', '했을', '뿐'], ['물고기를', '자세히', '그리지는', '않았습니다'], ['1800년대', '중반까지는'], ['눈과', '같은', '섬세한', '부분을', '그리지', '않았습니다'], ['그리고', '그림에', '장식도', '없었죠'], ['유명한', '귀족인', '사카이', '경은', '낚시광이었습니다'], ['그가', '대어를', '낚을', '때면'], ['그', '추억을', '간직하고', '싶었습니다'], ['큰', '도미를', '잡은', '그', '기억을', '말입니다'], ['그래서', '그는', '어부를', '시켜', '자신이', '잡은', '물고기를', '그리도록', '했죠'], ['그후부터는', '많은', '어부들이'], ['자신의', '교타쿠', '그림을', '들고', '사카이', '경한테', '왔습니다'], ['만약', '그', '그림이', '맘에', '들면'], ['사카이', '경은', '그', '어부에게', '그림을', '그리게', '했습니다'], ['에도시대에는', '많은', '교타쿠', '그림들이', '궁궐에', '걸렸습니다'], ['에도시대', '이후로는', '교타쿠의', '인기가', '떨어졌고'], ['점차', '퇴보했습니다'], ['오늘날', '교타쿠는', '다시', '인기', '있는', '예술이', '되었고'], ['많은', '사람들이', '즐깁니다'], ['사람들은', '교타쿠가', '어부들에게', '행운을', '가져', '온다고', '말합니다'], ['하지만', '이', '교타쿠', '예술은', '원형에서', '많이', '변형됐습니다'], ['오늘날', '많은', '화가들은', '혼자서', '시행착오를', '통해서', '배웁니다'], ['화가는', '그림을', '그리기', '전에'], ['물고기', '탁본을', '위한', '준비를', '해야', '합니다'], ['먼저', '화가는', '물고기를'], ['속을', '파낸', '표면위에', '올려', '놓습니다'], ['그리고', '지느러미들을', '쫙', '벌리고'], ['표면이', '마르도록', '핀을', '꽂습니다'], ['다음에는', '물고기를', '물로', '씻습니다'], ['딱본을', '뜨는', '방식에는'], ['두', '가지', '방법이', '있습니다'], ['간접적인', '방식은', '물고기', '위에', '촉촉한', '천이나', '종이를', '덮고'], ['밥풀을', '이용해', '붙이는', '걸로', '시작합니다'], ['그리고', '탐포라', '불리는'], ['실크로', '싼', '솜방망이를', '사용해서'], ['천이나', '종이에', '잉크를', '묻히고', '탁본을', '뜹니다'], ['이', '방법은', '높은', '기술과', '조심성을', '요구합니다'], ['물고기에서', '종이를', '떼어', '낼', '때'], ['종이가', '찢어지지', '않도록'], ['매우', '조심스럽게', '다뤄야', '합니다'], ['직접적인', '방식은'], ['화가가', '물고기', '위에', '직접', '잉크를', '칠하고'], ['촉촉한', '천이나', '종이를', '물고기', '위에', '대고', '부드럽게', '눌러줍니다'], ['이', '두가지', '방법을', '썼을', '때'], ['절대로', '똑같은', '그림이', '안나오지만'], ['둘', '다', '굉장히', '인상적인', '물고기', '그림이', '나옵니다'], ['그림의', '마지막', '단계는'], ['화가가', '도장을', '사용해서'], ['작품에', '싸인을', '하는', '것입니다'], ['그리고', '나서는', '작품을', '들고서', '말합니다'], ['이', '물고기는', '정확히', '이만큼', '큽니다', '라고', '말이죠'], ['만약', '우리가', '보이지', '않게', '된다면'], ['정말', '대단하지', '않을까요'], ['하', '그렇죠'], ['제', '말은', '사람들', '눈에', '띄지', '않게', '그들을', '몰래', '염탐', '할', '수', '있고'], ['그리고', '책임을', '지지', '않고서도'], ['우리가', '원하는', '것은', '무엇이든지', '할', '수', '있겠죠'], ['마술사들은', '없어지는', '환영을', '만들기', '위해'], ['빛을', '굴절시키는데', '사용하는', '전신', '거울들을'], ['어떻게', '이용하는지', '알아냈습니다'], ['과학자들은', '작은', '이차원적', '물체', '주위로'], ['빛줄기들을', '인도하기', '위해'], ['메타물질이라는', '것을', '만들어냈습니다'], ['카메라로', '사람의', '뒤에', '있는', '것도', '찍을', '수', '있고'], ['영상을', '비추는', '방법으로'], ['사람이', '투명하게', '보일', '수', '있도록', '할', '수', '있습니다']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JwP0PKl2rzbW",
        "colab_type": "code",
        "outputId": "f9b3ab17-b444-43ac-d4db-b50232e9bf7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "cell_type": "code",
      "source": [
        "model_ted.wv.most_similar('공공')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('시장', 0.9479732513427734),\n",
              " ('보건', 0.9461224675178528),\n",
              " ('건강', 0.9446510672569275),\n",
              " ('정보', 0.9420764446258545),\n",
              " ('정치', 0.9411664009094238),\n",
              " ('환경', 0.9409434795379639),\n",
              " ('산업', 0.9407810568809509),\n",
              " ('서비스', 0.9405919909477234),\n",
              " ('통신', 0.9390889406204224),\n",
              " ('정신', 0.9375384449958801)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 245
        }
      ]
    },
    {
      "metadata": {
        "id": "ra08RTWRr47F",
        "colab_type": "code",
        "outputId": "8771d7ef-8d33-4833-df35-2aaae1647451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "cell_type": "code",
      "source": [
        "model_ted.wv.most_similar('컴퓨터')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('세포', 0.8759253621101379),\n",
              " ('뇌', 0.8597628474235535),\n",
              " ('로봇', 0.8529554605484009),\n",
              " ('인터넷', 0.8487515449523926),\n",
              " ('시스템', 0.8465430736541748),\n",
              " ('유전자', 0.8440530300140381),\n",
              " ('공학', 0.8346738815307617),\n",
              " ('조직', 0.8346558213233948),\n",
              " ('줄기', 0.8337825536727905),\n",
              " ('네트워크', 0.8307371139526367)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "metadata": {
        "id": "dDy9fHlB6G9N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Install Korean font\n",
        "#https://colab.research.google.com/github/nicewook/datascience_exercise/blob/master/korean_font_on_matplotlib.ipynb\n",
        "!apt-get update -qq\n",
        "!apt-get install fonts-nanum* -qq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "13gTlaKTs_AM",
        "colab_type": "code",
        "outputId": "5f4474bf-4497-4da0-b23f-f0a1b02948ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        " \n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "\n",
        "#Install Korean font2\n",
        "import matplotlib.font_manager as fm \n",
        "path = '/usr/share/fonts/truetype/nanum/NanumGothicEco.ttf'  \n",
        "font_name = fm.FontProperties(fname=path, size=10).get_name()\n",
        "print(font_name)\n",
        "plt.rc('font', family=font_name)\n",
        "plt.rcParams['axes.unicode_minus'] = False # for minus marks\n",
        "fm._rebuild()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NanumGothic Eco\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GFYcq8bICPzx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Continuous Bag of Words**"
      ]
    },
    {
      "metadata": {
        "id": "wIu__7_AFHPq",
        "colab_type": "code",
        "outputId": "3d0f1989-4cda-49e4-f265-5ce48f9b7858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#using GPU.\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "sdgRCP1fCLYw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![대체 텍스트](https://upload.wikimedia.org/wikipedia/commons/a/a2/Cbow.png)"
      ]
    },
    {
      "metadata": {
        "id": "BmTOMelM02Yr",
        "colab_type": "code",
        "outputId": "4d6b9e4b-dcdd-4dde-a2be-308c2dff6618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10260
        }
      },
      "cell_type": "code",
      "source": [
        "#https://srijithr.gitlab.io/post/word2vec/\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "import sklearn\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "CONTEXT_SIZE = 3\n",
        "EMBEDDING_DIM = 10\n",
        "\n",
        "test_sentence = \"\"\"Empathy for the poor may not come easily to people who never experienced it. They may blame the victims and insist their predicament can be overcome through determination and hard work.\n",
        "But they may not realize that extreme poverty can be psychologically and physically incapacitating — a perpetual cycle of bad diets, health care and education exacerbated by the shaming and self-fulfilling prophecies that define it in the public imagination.\n",
        "Gordon Parks — perhaps more than any artist — saw poverty as “the most savage of all human afflictions” and realized the power of empathy to help us understand it. It was neither an abstract problem nor political symbol, but something he endured growing up destitute in rural Kansas and having spent years documenting poverty throughout the world, including the United States.\n",
        "That sensitivity informed “Freedom’s Fearful Foe: Poverty,” his celebrated photo essay published in Life magazine in June 1961. He took readers into the lives of a Brazilian boy, Flavio da Silva, and his family, who lived in the ramshackle Catacumba favela in the hills outside Rio de Janeiro. These stark photographs are the subject of a new book, “Gordon Parks: The Flavio Story” (Steidl/The Gordon Parks Foundation), which accompanies a traveling exhibition co-organized by the Ryerson Image Centre in Toronto, where it opens this week, and the J. Paul Getty Museum. Edited with texts by the exhibition’s co-curators, Paul Roth and Amanda Maddox, the book also includes a recent interview with Mr. da Silva and essays by Beatriz Jaguaribe, Maria Alice Rezende de Carvalho and Sérgio Burgi.\n",
        "\"\"\".split()\n",
        "# we should tokenize the input, but we will ignore that for now\n",
        "# build a list of tuples.  Each tuple is ([ word_i-2, word_i-1 ], target word)\n",
        "\n",
        "def get_key(word_id):\n",
        "    for key,val in word_to_ix.items():\n",
        "        if(val == word_id):\n",
        "            print(key)\n",
        "\n",
        "def cluster_embeddings(filename,nclusters):\n",
        "    X = np.load(filename)\n",
        "    kmeans = KMeans(n_clusters=nclusters, random_state=0).fit(X)\n",
        "    center = kmeans.cluster_centers_\n",
        "    distances = euclidean_distances(X,center)\n",
        "\n",
        "    for i in np.arange(0,distances.shape[1]):\n",
        "        word_id = np.argmin(distances[:,i])\n",
        "        print(word_id)\n",
        "        get_key(word_id)\n",
        "\n",
        "def read_data(file_path):\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    data = urllib.request.urlopen(file_path)\n",
        "    data = data.read().decode('utf8')\n",
        "    tokenized_data = word_tokenize(data)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    stop_words.update(['.',',',':',';','(',')','#','--','...','\"'])\n",
        "    cleaned_words = [ i for i in tokenized_data if i not in stop_words ]\n",
        "    return(cleaned_words)\n",
        "\n",
        "#test_sentence = read_data('https://www.gutenberg.org/files/57884/57884-0.txt')\n",
        "\n",
        "ngrams = []\n",
        "for i in range(len(test_sentence) - CONTEXT_SIZE):\n",
        "    tup = [test_sentence[j] for j in np.arange(i , i + CONTEXT_SIZE) ]\n",
        "    ngrams.append((tup,test_sentence[i + CONTEXT_SIZE]))\n",
        "# print the first 3, just so you can see what they look like\n",
        "\n",
        "\n",
        "vocab = set(test_sentence)\n",
        "print(\"Length of vocabulary\",len(vocab))\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "\n",
        "class CBOWModeler(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "        super(CBOWModeler, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
        "        self.linear2 = nn.Linear(128, vocab_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs).view((1, -1))  # -1 implies size inferred for that index from the size of the data\n",
        "        #print(np.mean(np.mean(self.linear2.weight.data.numpy())))\n",
        "        out1 = F.relu(self.linear1(embeds)) # output of first layer\n",
        "        out2 = self.linear2(out1) # output of second layer\n",
        "        log_probs = F.log_softmax(out2, dim=1)\n",
        "        return log_probs\n",
        "\n",
        "    def predict(self,input):\n",
        "        context_idxs = torch.tensor([word_to_ix[w] for w in input], dtype=torch.long) \n",
        "        res = self.forward(context_idxs) \n",
        "        res_arg = torch.argmax(res)\n",
        "        res_val, res_ind = res.sort(descending=True)\n",
        "        res_val = res_val[0][:3] \n",
        "        res_ind = res_ind[0][:3] \n",
        "        for arg in zip(res_val,res_ind):\n",
        "            print([(key,val,arg[0]) for key,val in word_to_ix.items() if val == arg[1]])\n",
        "\n",
        "#     def freeze_layer(self,layer):\n",
        "#         for name,child in model.named_children():\n",
        "#             print(name,child)\n",
        "#             if(name == layer):\n",
        "#                 for names,params in child.named_parameters():\n",
        "#                     print(names,params)\n",
        "#                     print(params.size())\n",
        "#                     params.requires_grad= False\n",
        "\n",
        "    def print_layer_parameters(self):\n",
        "        for name,child in model.named_children():\n",
        "                print(name,child)\n",
        "                for names,params in child.named_parameters():\n",
        "                    print(names,params)\n",
        "                    print(params.size())\n",
        "\n",
        "    def write_embedding_to_file(self,filename):\n",
        "        for i in self.embeddings.parameters():\n",
        "            weights = i.data.numpy()\n",
        "        np.save(filename,weights)\n",
        "\n",
        "\n",
        "\n",
        "losses = []\n",
        "loss_function = nn.NLLLoss()\n",
        "model = CBOWModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "# Freeze embedding layer\n",
        "# model.freeze_layer('embeddings')\n",
        "\n",
        "\n",
        "for epoch in range(500):\n",
        "    total_loss = 0\n",
        "    #------- Embedding layers are trained as well here ----#\n",
        "    #lookup_tensor = torch.tensor([word_to_ix[\"poor\"]], dtype=torch.long)\n",
        "    #hello_embed = model.embeddings(lookup_tensor)\n",
        "    #print(hello_embed)\n",
        "    # -----------------------------------------------------#\n",
        "\n",
        "    for context, target in ngrams:\n",
        "\n",
        "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
        "        # into integer indices and wrap them in tensors)\n",
        "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
        "        \n",
        "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
        "        # new instance, you need to zero out the gradients from the old\n",
        "        # instance\n",
        "        # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 3. Run the forward pass, getting log probabilities over next\n",
        "        # words\n",
        "        log_probs = model(context_idxs)\n",
        "        #print(log_probs)\n",
        "\n",
        "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
        "        # word wrapped in a tensor)\n",
        "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
        "        #print(loss)\n",
        "\n",
        "        # Step 5. Do the backward pass and update the gradient\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
        "        total_loss += loss.item()\n",
        "    print('total',total_loss)\n",
        "    losses.append(total_loss)\n",
        "# print('losses',losses)  # The loss decreased every iteration over the training data!\n",
        "\n",
        "#Print the model layer parameters\n",
        "print(model.print_layer_parameters())\n",
        "\n",
        "#Predict the next word given n context words\n",
        "model.predict(['of','all','human'])\n",
        "model.write_embedding_to_file('embeddings.npy')\n",
        "cluster_embeddings('embeddings.npy',2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of vocabulary 195\n",
            "total 1349.5488805770874\n",
            "total 1341.0166034698486\n",
            "total 1332.5900893211365\n",
            "total 1324.2677111625671\n",
            "total 1316.0376000404358\n",
            "total 1307.8953619003296\n",
            "total 1299.8298437595367\n",
            "total 1291.8424890041351\n",
            "total 1283.9322559833527\n",
            "total 1276.0939545631409\n",
            "total 1268.322156906128\n",
            "total 1260.61701130867\n",
            "total 1252.9829518795013\n",
            "total 1245.4230346679688\n",
            "total 1237.9486763477325\n",
            "total 1230.5609242916107\n",
            "total 1223.2549345493317\n",
            "total 1216.0292828083038\n",
            "total 1208.8866333961487\n",
            "total 1201.8235664367676\n",
            "total 1194.8301634788513\n",
            "total 1187.9026057720184\n",
            "total 1181.0344200134277\n",
            "total 1174.2225439548492\n",
            "total 1167.460349559784\n",
            "total 1160.7325067520142\n",
            "total 1154.037701845169\n",
            "total 1147.3620038032532\n",
            "total 1140.7017602920532\n",
            "total 1134.0429618358612\n",
            "total 1127.3816678524017\n",
            "total 1120.705332994461\n",
            "total 1114.011468410492\n",
            "total 1107.300431728363\n",
            "total 1100.566971540451\n",
            "total 1093.8043382167816\n",
            "total 1087.0158650875092\n",
            "total 1080.1863493919373\n",
            "total 1073.3179790973663\n",
            "total 1066.4066786766052\n",
            "total 1059.4520959854126\n",
            "total 1052.4552114009857\n",
            "total 1045.4063754081726\n",
            "total 1038.303092956543\n",
            "total 1031.145831823349\n",
            "total 1023.9266464710236\n",
            "total 1016.6456799507141\n",
            "total 1009.31254529953\n",
            "total 1001.9142842292786\n",
            "total 994.4511518478394\n",
            "total 986.9289000034332\n",
            "total 979.3415973186493\n",
            "total 971.6923394203186\n",
            "total 963.9738202095032\n",
            "total 956.1792404651642\n",
            "total 948.3121395111084\n",
            "total 940.3753457069397\n",
            "total 932.368706703186\n",
            "total 924.2901034355164\n",
            "total 916.133350610733\n",
            "total 907.9003813266754\n",
            "total 899.5894424915314\n",
            "total 891.2012977600098\n",
            "total 882.74010014534\n",
            "total 874.2027478218079\n",
            "total 865.5952394008636\n",
            "total 856.9117269515991\n",
            "total 848.1513328552246\n",
            "total 839.3107619285583\n",
            "total 830.3975489139557\n",
            "total 821.4056234359741\n",
            "total 812.3498222827911\n",
            "total 803.2194306850433\n",
            "total 794.0238869190216\n",
            "total 784.7576997280121\n",
            "total 775.4221622943878\n",
            "total 766.0205795764923\n",
            "total 756.5597324371338\n",
            "total 747.0356040000916\n",
            "total 737.4522356987\n",
            "total 727.806807756424\n",
            "total 718.1124892234802\n",
            "total 708.3650851249695\n",
            "total 698.5667748451233\n",
            "total 688.7252974510193\n",
            "total 678.8368940353394\n",
            "total 668.9085216522217\n",
            "total 658.942302942276\n",
            "total 648.9423122406006\n",
            "total 638.9165644645691\n",
            "total 628.8700823783875\n",
            "total 618.7966239452362\n",
            "total 608.7107517719269\n",
            "total 598.6129758358002\n",
            "total 588.5074009895325\n",
            "total 578.4024395942688\n",
            "total 568.3063051700592\n",
            "total 558.2193133831024\n",
            "total 548.1478083133698\n",
            "total 538.1021935939789\n",
            "total 528.084189414978\n",
            "total 518.1001145839691\n",
            "total 508.1578290462494\n",
            "total 498.2553234100342\n",
            "total 488.40246415138245\n",
            "total 478.60065841674805\n",
            "total 468.86590337753296\n",
            "total 459.1892259120941\n",
            "total 449.58901739120483\n",
            "total 440.0678086280823\n",
            "total 430.6214597225189\n",
            "total 421.27660298347473\n",
            "total 412.0125448703766\n",
            "total 402.8451623916626\n",
            "total 393.7870297431946\n",
            "total 384.82793378829956\n",
            "total 375.98203206062317\n",
            "total 367.24757289886475\n",
            "total 358.6333842277527\n",
            "total 350.13856291770935\n",
            "total 341.773903131485\n",
            "total 333.5278775691986\n",
            "total 325.42305612564087\n",
            "total 317.4457013607025\n",
            "total 309.6120026111603\n",
            "total 301.9112823009491\n",
            "total 294.3583378791809\n",
            "total 286.9431405067444\n",
            "total 279.6751756668091\n",
            "total 272.54502415657043\n",
            "total 265.5736231803894\n",
            "total 258.7358720302582\n",
            "total 252.05145740509033\n",
            "total 245.51902866363525\n",
            "total 239.13152313232422\n",
            "total 232.89596724510193\n",
            "total 226.80500864982605\n",
            "total 220.86305284500122\n",
            "total 215.06957697868347\n",
            "total 209.41657328605652\n",
            "total 203.9189269542694\n",
            "total 198.55541515350342\n",
            "total 193.34222030639648\n",
            "total 188.26493573188782\n",
            "total 183.33153176307678\n",
            "total 178.5329110622406\n",
            "total 173.87314891815186\n",
            "total 169.3456130027771\n",
            "total 164.9497034549713\n",
            "total 160.68334364891052\n",
            "total 156.54235792160034\n",
            "total 152.5263910293579\n",
            "total 148.63317918777466\n",
            "total 144.855815410614\n",
            "total 141.196368932724\n",
            "total 137.64882707595825\n",
            "total 134.21557188034058\n",
            "total 130.88625288009644\n",
            "total 127.66356992721558\n",
            "total 124.54260492324829\n",
            "total 121.51857137680054\n",
            "total 118.59181499481201\n",
            "total 115.75834321975708\n",
            "total 113.0161623954773\n",
            "total 110.36105823516846\n",
            "total 107.78924179077148\n",
            "total 105.3025393486023\n",
            "total 102.89568376541138\n",
            "total 100.5641827583313\n",
            "total 98.30610704421997\n",
            "total 96.12351322174072\n",
            "total 94.00727796554565\n",
            "total 91.96036577224731\n",
            "total 89.97724723815918\n",
            "total 88.05776929855347\n",
            "total 86.19677400588989\n",
            "total 84.39563035964966\n",
            "total 82.64984464645386\n",
            "total 80.95839929580688\n",
            "total 79.31897449493408\n",
            "total 77.729905128479\n",
            "total 76.18974924087524\n",
            "total 74.69511079788208\n",
            "total 73.24677181243896\n",
            "total 71.84145450592041\n",
            "total 70.47792863845825\n",
            "total 69.15476369857788\n",
            "total 67.87057781219482\n",
            "total 66.62457847595215\n",
            "total 65.4133791923523\n",
            "total 64.23809766769409\n",
            "total 63.09693479537964\n",
            "total 61.98639488220215\n",
            "total 60.90898036956787\n",
            "total 59.861074924468994\n",
            "total 58.841437339782715\n",
            "total 57.850008964538574\n",
            "total 56.88630199432373\n",
            "total 55.948933124542236\n",
            "total 55.035850524902344\n",
            "total 54.14710330963135\n",
            "total 53.28257179260254\n",
            "total 52.44021940231323\n",
            "total 51.62071657180786\n",
            "total 50.821598052978516\n",
            "total 50.043673038482666\n",
            "total 49.284423828125\n",
            "total 48.54478979110718\n",
            "total 47.82391309738159\n",
            "total 47.12112474441528\n",
            "total 46.43497943878174\n",
            "total 45.766300201416016\n",
            "total 45.11341905593872\n",
            "total 44.47620630264282\n",
            "total 43.85391902923584\n",
            "total 43.24729871749878\n",
            "total 42.653953075408936\n",
            "total 42.074793338775635\n",
            "total 41.50915765762329\n",
            "total 40.95626449584961\n",
            "total 40.416053771972656\n",
            "total 39.88758611679077\n",
            "total 39.371273040771484\n",
            "total 38.86658334732056\n",
            "total 38.37269735336304\n",
            "total 37.88951921463013\n",
            "total 37.416812896728516\n",
            "total 36.95433759689331\n",
            "total 36.50121784210205\n",
            "total 36.058340072631836\n",
            "total 35.624464988708496\n",
            "total 35.19932508468628\n",
            "total 34.78335952758789\n",
            "total 34.375648021698\n",
            "total 33.976459980010986\n",
            "total 33.58478832244873\n",
            "total 33.20184278488159\n",
            "total 32.8252592086792\n",
            "total 32.4574499130249\n",
            "total 32.0960693359375\n",
            "total 31.74167490005493\n",
            "total 31.394141674041748\n",
            "total 31.053404331207275\n",
            "total 30.719141960144043\n",
            "total 30.390873432159424\n",
            "total 30.068991661071777\n",
            "total 29.752888202667236\n",
            "total 29.442934036254883\n",
            "total 29.1378436088562\n",
            "total 28.83931016921997\n",
            "total 28.545767784118652\n",
            "total 28.257022380828857\n",
            "total 27.973960876464844\n",
            "total 27.69594955444336\n",
            "total 27.422537803649902\n",
            "total 27.153619289398193\n",
            "total 26.88992214202881\n",
            "total 26.630290985107422\n",
            "total 26.37531089782715\n",
            "total 26.124778747558594\n",
            "total 25.878149032592773\n",
            "total 25.635725498199463\n",
            "total 25.39754009246826\n",
            "total 25.162909984588623\n",
            "total 24.932377815246582\n",
            "total 24.705350875854492\n",
            "total 24.482380390167236\n",
            "total 24.26252317428589\n",
            "total 24.04642105102539\n",
            "total 23.83362913131714\n",
            "total 23.624410152435303\n",
            "total 23.41833734512329\n",
            "total 23.215283393859863\n",
            "total 23.015509605407715\n",
            "total 22.818883419036865\n",
            "total 22.625061511993408\n",
            "total 22.4343204498291\n",
            "total 22.24646806716919\n",
            "total 22.061406135559082\n",
            "total 21.878764152526855\n",
            "total 21.699475288391113\n",
            "total 21.52220392227173\n",
            "total 21.3477840423584\n",
            "total 21.17595148086548\n",
            "total 21.006503582000732\n",
            "total 20.839431762695312\n",
            "total 20.674911975860596\n",
            "total 20.51262855529785\n",
            "total 20.352559089660645\n",
            "total 20.194797039031982\n",
            "total 20.03911828994751\n",
            "total 19.885845184326172\n",
            "total 19.73452377319336\n",
            "total 19.585270404815674\n",
            "total 19.437935829162598\n",
            "total 19.29281520843506\n",
            "total 19.14957332611084\n",
            "total 19.008116722106934\n",
            "total 18.868639945983887\n",
            "total 18.731090545654297\n",
            "total 18.5953049659729\n",
            "total 18.461113929748535\n",
            "total 18.32887887954712\n",
            "total 18.198378562927246\n",
            "total 18.069427967071533\n",
            "total 17.94219732284546\n",
            "total 17.816505908966064\n",
            "total 17.692516803741455\n",
            "total 17.57000160217285\n",
            "total 17.448979377746582\n",
            "total 17.329526901245117\n",
            "total 17.211639881134033\n",
            "total 17.095101356506348\n",
            "total 16.979870319366455\n",
            "total 16.866300106048584\n",
            "total 16.753963470458984\n",
            "total 16.642909049987793\n",
            "total 16.533379554748535\n",
            "total 16.424877166748047\n",
            "total 16.317965030670166\n",
            "total 16.21215534210205\n",
            "total 16.10763168334961\n",
            "total 16.004241943359375\n",
            "total 15.902260780334473\n",
            "total 15.801216125488281\n",
            "total 15.701571464538574\n",
            "total 15.602810859680176\n",
            "total 15.50544261932373\n",
            "total 15.409021377563477\n",
            "total 15.313642501831055\n",
            "total 15.219484329223633\n",
            "total 15.1262845993042\n",
            "total 15.034201622009277\n",
            "total 14.943037986755371\n",
            "total 14.852840423583984\n",
            "total 14.763753890991211\n",
            "total 14.675583839416504\n",
            "total 14.588303565979004\n",
            "total 14.502102851867676\n",
            "total 14.416712760925293\n",
            "total 14.332256317138672\n",
            "total 14.248733520507812\n",
            "total 14.165995597839355\n",
            "total 14.084282875061035\n",
            "total 14.0033597946167\n",
            "total 13.923203468322754\n",
            "total 13.844012260437012\n",
            "total 13.765542984008789\n",
            "total 13.688013076782227\n",
            "total 13.61111831665039\n",
            "total 13.535094261169434\n",
            "total 13.459847450256348\n",
            "total 13.385364532470703\n",
            "total 13.311574935913086\n",
            "total 13.238568305969238\n",
            "total 13.166314125061035\n",
            "total 13.094765663146973\n",
            "total 13.02386474609375\n",
            "total 12.953782081604004\n",
            "total 12.884212493896484\n",
            "total 12.815497398376465\n",
            "total 12.74736499786377\n",
            "total 12.679945945739746\n",
            "total 12.61310863494873\n",
            "total 12.546960830688477\n",
            "total 12.481395721435547\n",
            "total 12.416547775268555\n",
            "total 12.3522367477417\n",
            "total 12.288556098937988\n",
            "total 12.225446701049805\n",
            "total 12.16297435760498\n",
            "total 12.101103782653809\n",
            "total 12.039656639099121\n",
            "total 11.978960990905762\n",
            "total 11.91872501373291\n",
            "total 11.859102249145508\n",
            "total 11.799982070922852\n",
            "total 11.741388320922852\n",
            "total 11.683370590209961\n",
            "total 11.625889778137207\n",
            "total 11.568878173828125\n",
            "total 11.512371063232422\n",
            "total 11.45643138885498\n",
            "total 11.400962829589844\n",
            "total 11.345966339111328\n",
            "total 11.291467666625977\n",
            "total 11.237332344055176\n",
            "total 11.183874130249023\n",
            "total 11.130824089050293\n",
            "total 11.078143119812012\n",
            "total 11.026022911071777\n",
            "total 10.974254608154297\n",
            "total 10.923008918762207\n",
            "total 10.872167587280273\n",
            "total 10.821759223937988\n",
            "total 10.771778106689453\n",
            "total 10.722219467163086\n",
            "total 10.673151969909668\n",
            "total 10.624360084533691\n",
            "total 10.576090812683105\n",
            "total 10.528166770935059\n",
            "total 10.480656623840332\n",
            "total 10.433509826660156\n",
            "total 10.386795043945312\n",
            "total 10.340468406677246\n",
            "total 10.294473648071289\n",
            "total 10.248892784118652\n",
            "total 10.203673362731934\n",
            "total 10.158839225769043\n",
            "total 10.114349365234375\n",
            "total 10.070146560668945\n",
            "total 10.026437759399414\n",
            "total 9.983004570007324\n",
            "total 9.939916610717773\n",
            "total 9.8971529006958\n",
            "total 9.854734420776367\n",
            "total 9.812668800354004\n",
            "total 9.770939826965332\n",
            "total 9.72952651977539\n",
            "total 9.688397407531738\n",
            "total 9.647627830505371\n",
            "total 9.607178688049316\n",
            "total 9.567010879516602\n",
            "total 9.527145385742188\n",
            "total 9.487622261047363\n",
            "total 9.448365211486816\n",
            "total 9.40944766998291\n",
            "total 9.370768547058105\n",
            "total 9.332486152648926\n",
            "total 9.294371604919434\n",
            "total 9.256650924682617\n",
            "total 9.219083786010742\n",
            "total 9.181949615478516\n",
            "total 9.144993782043457\n",
            "total 9.10830307006836\n",
            "total 9.071914672851562\n",
            "total 9.035819053649902\n",
            "total 8.999948501586914\n",
            "total 8.964348793029785\n",
            "total 8.929015159606934\n",
            "total 8.893941879272461\n",
            "total 8.859079360961914\n",
            "total 8.82449722290039\n",
            "total 8.790183067321777\n",
            "total 8.756118774414062\n",
            "total 8.722273826599121\n",
            "total 8.688672065734863\n",
            "total 8.655281066894531\n",
            "total 8.622183799743652\n",
            "total 8.58927059173584\n",
            "total 8.55663776397705\n",
            "total 8.524177551269531\n",
            "total 8.491960525512695\n",
            "total 8.459991455078125\n",
            "total 8.428243637084961\n",
            "total 8.396712303161621\n",
            "total 8.36534309387207\n",
            "total 8.334266662597656\n",
            "total 8.303350448608398\n",
            "total 8.272683143615723\n",
            "total 8.242192268371582\n",
            "total 8.21192455291748\n",
            "total 8.181851387023926\n",
            "total 8.151998519897461\n",
            "total 8.12231731414795\n",
            "total 8.092905044555664\n",
            "total 8.063597679138184\n",
            "total 8.034553527832031\n",
            "total 8.005643844604492\n",
            "total 7.97698974609375\n",
            "total 7.9484710693359375\n",
            "total 7.920180320739746\n",
            "total 7.892041206359863\n",
            "total 7.864132881164551\n",
            "total 7.836350440979004\n",
            "total 7.80881404876709\n",
            "total 7.781371116638184\n",
            "total 7.754177093505859\n",
            "total 7.727158546447754\n",
            "total 7.700265884399414\n",
            "total 7.673543930053711\n",
            "total 7.647051811218262\n",
            "total 7.620689392089844\n",
            "total 7.59449577331543\n",
            "total 7.56846809387207\n",
            "total 7.542636871337891\n",
            "total 7.516932487487793\n",
            "total 7.491397857666016\n",
            "total 7.466014862060547\n",
            "total 7.440801620483398\n",
            "total 7.415748596191406\n",
            "total 7.390838623046875\n",
            "total 7.366095542907715\n",
            "total 7.341500282287598\n",
            "total 7.317063331604004\n",
            "total 7.2927751541137695\n",
            "total 7.268614768981934\n",
            "total 7.244625091552734\n",
            "total 7.220787048339844\n",
            "total 7.197075843811035\n",
            "embeddings Embedding(195, 10)\n",
            "weight Parameter containing:\n",
            "tensor([[-1.5804, -0.7661, -0.6925,  ..., -1.6733, -0.7797,  0.3089],\n",
            "        [-0.7854, -0.2636, -0.2292,  ..., -1.2330,  0.7381,  0.2212],\n",
            "        [ 0.9049,  0.2681, -0.6877,  ..., -1.5668,  0.0851, -0.6155],\n",
            "        ...,\n",
            "        [ 0.4320, -0.2256,  1.4903,  ...,  0.9433,  0.7852,  0.3310],\n",
            "        [ 0.0893,  0.3843,  0.4104,  ...,  0.5822,  0.5549,  0.5485],\n",
            "        [ 0.0782, -1.5883, -0.3160,  ...,  1.0686, -1.0775, -1.3527]],\n",
            "       requires_grad=True)\n",
            "torch.Size([195, 10])\n",
            "linear1 Linear(in_features=30, out_features=128, bias=True)\n",
            "weight Parameter containing:\n",
            "tensor([[-2.7088e-02,  4.2652e-01,  1.7191e-01,  ..., -1.0714e-01,\n",
            "         -9.5701e-02,  4.2378e-01],\n",
            "        [ 3.5982e-02,  1.2696e-01, -4.1219e-01,  ...,  3.2398e-01,\n",
            "          1.6718e-04, -3.3660e-01],\n",
            "        [-2.3402e-01, -1.5538e-01, -1.7793e-01,  ..., -2.8681e-01,\n",
            "          2.1154e-01, -2.3600e-01],\n",
            "        ...,\n",
            "        [-7.3892e-02, -1.7917e-01, -4.1804e-01,  ..., -1.5609e-01,\n",
            "          1.9350e-01, -1.1118e-01],\n",
            "        [ 1.4178e-01,  2.4810e-01,  1.5110e-01,  ...,  1.2703e-01,\n",
            "         -7.9471e-02, -3.1329e-01],\n",
            "        [ 1.8542e-01, -1.0622e-01, -3.1322e-02,  ...,  1.4996e-01,\n",
            "          1.8480e-02, -2.3866e-01]], requires_grad=True)\n",
            "torch.Size([128, 30])\n",
            "bias Parameter containing:\n",
            "tensor([ 0.5025,  0.2679,  0.3388,  0.4708,  0.6707,  0.3001,  0.5764,  0.4498,\n",
            "         0.1102,  0.2216,  0.3175,  0.4492, -0.0051,  0.1405,  0.3649,  0.4678,\n",
            "         0.1933,  0.3535,  0.3144,  0.1344,  0.4191,  0.5778,  0.0971,  0.0292,\n",
            "         0.5439,  0.2299,  0.4348,  0.1035,  0.1134,  0.5210,  0.2220,  0.3551,\n",
            "         0.0111,  0.4081,  0.3085,  0.0571,  0.4367,  0.3228,  0.2380,  0.4351,\n",
            "         0.3997,  0.3915,  0.0264,  0.3280,  0.0381,  0.2291,  0.4179,  0.1039,\n",
            "         0.4973,  0.4439,  0.3222,  0.3064,  0.2373,  0.2150,  0.4269,  0.2822,\n",
            "         0.1740,  0.1378,  0.3636,  0.3103,  0.1332,  0.3269,  0.1716,  0.2358,\n",
            "        -0.0089,  0.2969,  0.2366,  0.2580,  0.3988,  0.4167,  0.3142,  0.3236,\n",
            "         0.1502,  0.4869,  0.1303,  0.3298,  0.5643,  0.2898,  0.1058,  0.2180,\n",
            "         0.0371,  0.0803,  0.2963,  0.5528,  0.3091,  0.3224,  0.2209,  0.1003,\n",
            "         0.2089,  0.1179,  0.3670,  0.4312,  0.4935,  0.0503,  0.4474, -0.0489,\n",
            "         0.5120,  0.0344,  0.1700,  0.1960,  0.4589,  0.2484,  0.4016,  0.5248,\n",
            "         0.1982,  0.3732,  0.3507,  0.0277,  0.0580,  0.5694,  0.1240,  0.3814,\n",
            "         0.2457,  0.2352,  0.1887,  0.2239,  0.1670,  0.1740,  0.3138,  0.2098,\n",
            "         0.3104,  0.2322,  0.4872,  0.4275,  0.4994,  0.0845,  0.0251,  0.1758],\n",
            "       requires_grad=True)\n",
            "torch.Size([128])\n",
            "linear2 Linear(in_features=128, out_features=195, bias=True)\n",
            "weight Parameter containing:\n",
            "tensor([[ 0.0806,  0.2165, -0.0555,  ...,  0.0500,  0.0485,  0.1087],\n",
            "        [ 0.1353, -0.0292, -0.0445,  ..., -0.0614, -0.1172, -0.0394],\n",
            "        [ 0.0065, -0.0978,  0.1404,  ...,  0.1137, -0.0511, -0.1242],\n",
            "        ...,\n",
            "        [ 0.1543,  0.1620, -0.0530,  ..., -0.0760, -0.0351, -0.0819],\n",
            "        [ 0.0732,  0.0025, -0.1323,  ..., -0.1187,  0.0833,  0.0033],\n",
            "        [ 0.3377, -0.0232, -0.0087,  ...,  0.0313,  0.1172,  0.0363]],\n",
            "       requires_grad=True)\n",
            "torch.Size([195, 128])\n",
            "bias Parameter containing:\n",
            "tensor([-0.0140, -0.0805, -0.0741, -0.0673,  0.0349, -0.0214,  0.0566, -0.0096,\n",
            "        -0.1163, -0.0753, -0.0365, -0.0188,  0.0436, -0.0180, -0.0115, -0.0955,\n",
            "        -0.0461, -0.0644, -0.0158, -0.1324, -0.0876,  0.0733, -0.0036,  0.1427,\n",
            "         0.0078,  0.0026, -0.0502,  0.0817, -0.0720, -0.0469, -0.0376, -0.0314,\n",
            "         0.0798, -0.0367, -0.0874,  0.0840, -0.0630, -0.0718,  0.0059, -0.0691,\n",
            "        -0.0205, -0.0687, -0.1208,  0.0474, -0.0208,  0.0417,  0.0826, -0.0296,\n",
            "         0.0765, -0.0469, -0.0452,  0.0061, -0.0559, -0.0205, -0.0439,  0.0740,\n",
            "         0.0471, -0.0414, -0.0101,  0.0580, -0.0449,  0.0656, -0.0262,  0.0006,\n",
            "        -0.0526,  0.0073,  0.0563,  0.0533,  0.0898,  0.0466, -0.0548,  0.0423,\n",
            "         0.0333,  0.0466, -0.0546, -0.0007,  0.0151,  0.0268, -0.0401,  0.0644,\n",
            "         0.0565,  0.0165, -0.0851,  0.0311,  0.0155,  0.0123, -0.0177, -0.0838,\n",
            "        -0.0137, -0.0567, -0.0746, -0.1000, -0.1356,  0.0647,  0.0066, -0.0645,\n",
            "         0.0281,  0.0813,  0.0762,  0.0251, -0.0957,  0.0499, -0.0528,  0.1054,\n",
            "        -0.0039, -0.0526,  0.0204, -0.0935,  0.0244, -0.0115, -0.0204,  0.0174,\n",
            "         0.0483, -0.0858, -0.0137,  0.0324,  0.0148, -0.1105,  0.0533,  0.0652,\n",
            "        -0.0363, -0.0239,  0.0253,  0.1231, -0.0751,  0.0275,  0.0662,  0.0265,\n",
            "        -0.0446, -0.0060, -0.0007, -0.0957, -0.0908, -0.0069,  0.0145, -0.0700,\n",
            "        -0.0065,  0.0194,  0.0354,  0.0722, -0.0411,  0.0908, -0.0287, -0.1333,\n",
            "         0.0131,  0.0490,  0.0902, -0.0136, -0.0044,  0.0499,  0.0670, -0.0321,\n",
            "         0.0514, -0.0641,  0.0320,  0.0237, -0.0474,  0.0542, -0.0890,  0.0551,\n",
            "        -0.0948,  0.0181,  0.0235,  0.0491, -0.0299,  0.0904,  0.0295,  0.0368,\n",
            "        -0.0584, -0.0254,  0.0566, -0.0692,  0.0820, -0.0035, -0.0691, -0.0685,\n",
            "         0.0647,  0.0747, -0.0450,  0.1247,  0.0232, -0.0505, -0.0115, -0.0939,\n",
            "         0.0654, -0.0214,  0.1410,  0.0150, -0.0311, -0.0444,  0.0508,  0.0665,\n",
            "         0.0917,  0.0341,  0.0620], requires_grad=True)\n",
            "torch.Size([195])\n",
            "None\n",
            "[('afflictions”', 113, tensor(-0.0158, grad_fn=<SelectBackward>))]\n",
            "[('by', 35, tensor(-5.5729, grad_fn=<SelectBackward>))]\n",
            "[('a', 55, tensor(-5.7889, grad_fn=<SelectBackward>))]\n",
            "145\n",
            "health\n",
            "193\n",
            "Ryerson\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ESJnr7KeBvHx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Skipgrams**"
      ]
    },
    {
      "metadata": {
        "id": "Ks23j5wIBjMK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![대체 텍스트](https://upload.wikimedia.org/wikipedia/commons/9/95/Skip-gram.png)"
      ]
    },
    {
      "metadata": {
        "id": "7MhhR13z19bT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9707
        },
        "outputId": "3d9a481f-2ff6-4c28-b843-5b8f54507d93"
      },
      "cell_type": "code",
      "source": [
        "#https://srijithr.gitlab.io/post/word2vec/\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "import sklearn\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "CONTEXT_SIZE = 3\n",
        "EMBEDDING_DIM = 10\n",
        "\n",
        "def get_key(word_id):\n",
        "    for key,val in word_to_ix.items():\n",
        "        if(val == word_id):\n",
        "            print(key)\n",
        "\n",
        "\n",
        "def cluster_embeddings(filename,nclusters):\n",
        "    X = np.load(filename)\n",
        "    kmeans = KMeans(n_clusters=nclusters, random_state=0).fit(X)\n",
        "    center = kmeans.cluster_centers_\n",
        "    distances = euclidean_distances(X,center)\n",
        "\n",
        "    for i in np.arange(0,distances.shape[1]):\n",
        "        word_id = np.argmin(distances[:,i])\n",
        "        print(word_id)\n",
        "        get_key(word_id)\n",
        "\n",
        "def read_data(file_path):\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    data = urllib.request.urlopen(file_path)\n",
        "    data = data.read().decode('utf8')\n",
        "    tokenized_data = word_tokenize(data)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    stop_words.update(['.',',',':',';','(',')','#','--','...','\"'])\n",
        "    cleaned_words = [ i for i in tokenized_data if i not in stop_words ]\n",
        "    return(cleaned_words)\n",
        "\n",
        "\n",
        "test_sentence = \"\"\"Empathy for the poor may not come easily to people who never experienced it. They may blame the victims and insist their predicament can be overcome through determination and hard work.\n",
        "But they may not realize that extreme poverty can be psychologically and physically incapacitating — a perpetual cycle of bad diets, health care and education exacerbated by the shaming and self-fulfilling prophecies that define it in the public imagination.\n",
        "Gordon Parks — perhaps more than any artist — saw poverty as “the most savage of all human afflictions” and realized the power of empathy to help us understand it. It was neither an abstract problem nor political symbol, but something he endured growing up destitute in rural Kansas and having spent years documenting poverty throughout the world, including the United States.\n",
        "That sensitivity informed “Freedom’s Fearful Foe: Poverty,” his celebrated photo essay published in Life magazine in June 1961. He took readers into the lives of a Brazilian boy, Flavio da Silva, and his family, who lived in the ramshackle Catacumba favela in the hills outside Rio de Janeiro. These stark photographs are the subject of a new book, “Gordon Parks: The Flavio Story” (Steidl/The Gordon Parks Foundation), which accompanies a traveling exhibition co-organized by the Ryerson Image Centre in Toronto, where it opens this week, and the J. Paul Getty Museum. Edited with texts by the exhibition’s co-curators, Paul Roth and Amanda Maddox, the book also includes a recent interview with Mr. da Silva and essays by Beatriz Jaguaribe, Maria Alice Rezende de Carvalho and Sérgio Burgi.\n",
        "\"\"\".split()\n",
        "# we should tokenize the input, but we will ignore that for now\n",
        "# build a list of tuples.  Each tuple is ([ word_i-2, word_i-1 ], target word)\n",
        "\n",
        "#test_sentence = read_data('https://www.gutenberg.org/files/57884/57884-0.txt')\n",
        "\n",
        "ngrams = []\n",
        "for i in range(len(test_sentence) - CONTEXT_SIZE):\n",
        "    tup = [test_sentence[j] for j in np.arange(i + 1 , i + CONTEXT_SIZE + 1) ]\n",
        "    ngrams.append((test_sentence[i],tup))\n",
        "# print the first 3, just so you can see what they look like\n",
        "#print(ngrams)\n",
        "\n",
        "\n",
        "vocab = set(test_sentence)\n",
        "print(\"Length of vocabulary\",len(vocab))\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "\n",
        "class SkipgramModeler(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "        super(SkipgramModeler, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(embedding_dim, 128)\n",
        "        self.linear2 = nn.Linear(128, context_size * vocab_size)\n",
        "        #self.parameters['context_size'] = context_size\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs).view((1, -1))  # -1 implies size inferred for that index from the size of the data\n",
        "        #print(np.mean(np.mean(self.linear2.weight.data.numpy())))\n",
        "        out1 = F.relu(self.linear1(embeds)) # output of first layer\n",
        "        out2 = self.linear2(out1)           # output of second layer\n",
        "        #print(embeds)\n",
        "        log_probs = F.log_softmax(out2, dim=1).view(CONTEXT_SIZE,-1)\n",
        "        return log_probs\n",
        "\n",
        "    def predict(self,input):\n",
        "        context_idxs = torch.tensor([word_to_ix[input]], dtype=torch.long)\n",
        "        res = self.forward(context_idxs)\n",
        "        res_arg = torch.argmax(res)\n",
        "        res_val, res_ind = res.sort(descending=True)\n",
        "        indices = [res_ind[i][0] for i in np.arange(0,3)]\n",
        "#         for arg in indices:\n",
        "#             print( [ (key, val) for key,val in word_to_ix.items() if val == arg ])\n",
        "\n",
        "\n",
        "#     def freeze_layer(self,layer):\n",
        "#         for name,child in model.named_children():\n",
        "#             print(name,child)\n",
        "#             if(name == layer):\n",
        "#                 for names,params in child.named_parameters():\n",
        "#                     print(names,params)\n",
        "#                     print(params.size())\n",
        "#                     params.requires_grad= False\n",
        "\n",
        "    def print_layer_parameters(self):\n",
        "        for name,child in model.named_children():\n",
        "                print(name,child)\n",
        "                for names,params in child.named_parameters():\n",
        "                    print(names,params)\n",
        "                    print(params.size())\n",
        "\n",
        "    def write_embedding_to_file(self,filename):\n",
        "        for i in self.embeddings.parameters():\n",
        "            weights = i.data.numpy()\n",
        "        np.save(filename,weights)\n",
        "\n",
        "\n",
        "losses = []\n",
        "loss_function = nn.NLLLoss()\n",
        "model = SkipgramModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "# Freeze embedding layer\n",
        "#model.freeze_layer('embeddings')\n",
        "\n",
        "for epoch in range(550):\n",
        "    total_loss = 0\n",
        "    #------- Embedding layers are trained as well here ----#\n",
        "    #lookup_tensor = torch.tensor([word_to_ix[\"poor\"]], dtype=torch.long)\n",
        "    #hello_embed = model.embeddings(lookup_tensor)\n",
        "    #print(hello_embed)\n",
        "    # -----------------------------------------------------#\n",
        "\n",
        "    model.predict('psychologically')\n",
        "\n",
        "    for context, target in ngrams:\n",
        "\n",
        "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
        "        # into integer indices and wrap them in tensors)\n",
        "        #print(context,target)\n",
        "\n",
        "\n",
        "        context_idxs = torch.tensor([word_to_ix[context]], dtype=torch.long)\n",
        "        #print(\"Context id\",context_idxs)\n",
        "\n",
        "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
        "        # new instance, you need to zero out the gradients from the old\n",
        "        # instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 3. Run the forward pass, getting log probabilities over next\n",
        "        # words\n",
        "        log_probs = model(context_idxs)\n",
        "        #print(log_probs)\n",
        "\n",
        "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
        "        # word wrapped in a tensor)\n",
        "        target_list = torch.tensor([word_to_ix[w] for w in target], dtype=torch.long)\n",
        "        loss = loss_function(log_probs, target_list)\n",
        "        #print(loss)\n",
        "\n",
        "        # Step 5. Do the backward pass and update the gradient\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
        "        total_loss += loss.item()\n",
        "    print(total_loss)\n",
        "    losses.append(total_loss)\n",
        "#print(losses)  # The loss decreased every iteration over the training data!\n",
        "\n",
        "#Print the model layer parameters\n",
        "#model.print_layer_parameters()\n",
        "\n",
        "#Predict the next word given n context words\n",
        "model.predict('psychologically')\n",
        "model.write_embedding_to_file('embeddings_skipgrams.npy')\n",
        "cluster_embeddings('embeddings_skipgrams.npy',5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of vocabulary 195\n",
            "1638.4615502357483\n",
            "1635.9240007400513\n",
            "1633.403148651123\n",
            "1630.8984184265137\n",
            "1628.4083499908447\n",
            "1625.9311332702637\n",
            "1623.4669008255005\n",
            "1621.0151329040527\n",
            "1618.5751128196716\n",
            "1616.1457662582397\n",
            "1613.7263226509094\n",
            "1611.315972328186\n",
            "1608.9144911766052\n",
            "1606.5211324691772\n",
            "1604.1355395317078\n",
            "1601.7573890686035\n",
            "1599.385597229004\n",
            "1597.0204801559448\n",
            "1594.661952972412\n",
            "1592.309163570404\n",
            "1589.9618310928345\n",
            "1587.6193866729736\n",
            "1585.2817578315735\n",
            "1582.9486985206604\n",
            "1580.6201753616333\n",
            "1578.296314239502\n",
            "1575.9768886566162\n",
            "1573.6614785194397\n",
            "1571.3503098487854\n",
            "1569.0439100265503\n",
            "1566.7426753044128\n",
            "1564.4461741447449\n",
            "1562.1548705101013\n",
            "1559.8684539794922\n",
            "1557.5869545936584\n",
            "1555.310601234436\n",
            "1553.0399689674377\n",
            "1550.7757172584534\n",
            "1548.5182428359985\n",
            "1546.2681169509888\n",
            "1544.0264735221863\n",
            "1541.7934303283691\n",
            "1539.568899154663\n",
            "1537.353190422058\n",
            "1535.1466813087463\n",
            "1532.9497385025024\n",
            "1530.7628536224365\n",
            "1528.58642911911\n",
            "1526.4202723503113\n",
            "1524.264654636383\n",
            "1522.1196756362915\n",
            "1519.9856386184692\n",
            "1517.8626103401184\n",
            "1515.7503690719604\n",
            "1513.6491436958313\n",
            "1511.5582432746887\n",
            "1509.4779815673828\n",
            "1507.4074659347534\n",
            "1505.3470830917358\n",
            "1503.296944618225\n",
            "1501.2552590370178\n",
            "1499.2224340438843\n",
            "1497.1984281539917\n",
            "1495.182207107544\n",
            "1493.1728286743164\n",
            "1491.169755935669\n",
            "1489.1724615097046\n",
            "1487.1805033683777\n",
            "1485.1938276290894\n",
            "1483.2113614082336\n",
            "1481.2315015792847\n",
            "1479.2534823417664\n",
            "1477.277973651886\n",
            "1475.3034181594849\n",
            "1473.3295180797577\n",
            "1471.3555212020874\n",
            "1469.3815650939941\n",
            "1467.407166004181\n",
            "1465.4305646419525\n",
            "1463.452109336853\n",
            "1461.4716613292694\n",
            "1459.4888129234314\n",
            "1457.5031154155731\n",
            "1455.5138761997223\n",
            "1453.5201833248138\n",
            "1451.522748708725\n",
            "1449.5209381580353\n",
            "1447.514122724533\n",
            "1445.501930475235\n",
            "1443.4836637973785\n",
            "1441.4588613510132\n",
            "1439.4281487464905\n",
            "1437.3915672302246\n",
            "1435.3483211994171\n",
            "1433.2982428073883\n",
            "1431.2419910430908\n",
            "1429.1783957481384\n",
            "1427.106858253479\n",
            "1425.0275688171387\n",
            "1422.9405589103699\n",
            "1420.8457579612732\n",
            "1418.742335319519\n",
            "1416.630755186081\n",
            "1414.5098078250885\n",
            "1412.3811733722687\n",
            "1410.2438986301422\n",
            "1408.0978753566742\n",
            "1405.9429404735565\n",
            "1403.7788047790527\n",
            "1401.606455564499\n",
            "1399.4242460727692\n",
            "1397.2330935001373\n",
            "1395.03271484375\n",
            "1392.8227632045746\n",
            "1390.6036486625671\n",
            "1388.3749396800995\n",
            "1386.1364829540253\n",
            "1383.8886063098907\n",
            "1381.6314988136292\n",
            "1379.364895582199\n",
            "1377.0885000228882\n",
            "1374.8018140792847\n",
            "1372.505436182022\n",
            "1370.1994705200195\n",
            "1367.8832652568817\n",
            "1365.5571854114532\n",
            "1363.220627784729\n",
            "1360.874766588211\n",
            "1358.518410205841\n",
            "1356.1519358158112\n",
            "1353.7753715515137\n",
            "1351.3878092765808\n",
            "1348.991250038147\n",
            "1346.5833132266998\n",
            "1344.165545463562\n",
            "1341.7365732192993\n",
            "1339.298088312149\n",
            "1336.8481245040894\n",
            "1334.388123512268\n",
            "1331.917509317398\n",
            "1329.4364292621613\n",
            "1326.9446332454681\n",
            "1324.4422054290771\n",
            "1321.9289102554321\n",
            "1319.404770374298\n",
            "1316.8699996471405\n",
            "1314.3239707946777\n",
            "1311.7677431106567\n",
            "1309.2008004188538\n",
            "1306.622540473938\n",
            "1304.0341720581055\n",
            "1301.4336035251617\n",
            "1298.823261499405\n",
            "1296.2023856639862\n",
            "1293.56995511055\n",
            "1290.9260430335999\n",
            "1288.272804737091\n",
            "1285.6081602573395\n",
            "1282.9318289756775\n",
            "1280.24569106102\n",
            "1277.5483829975128\n",
            "1274.8410651683807\n",
            "1272.123356103897\n",
            "1269.395750284195\n",
            "1266.657126903534\n",
            "1263.9088199138641\n",
            "1261.150262594223\n",
            "1258.3813922405243\n",
            "1255.6021370887756\n",
            "1252.8129301071167\n",
            "1250.0129129886627\n",
            "1247.2037107944489\n",
            "1244.383245229721\n",
            "1241.5542166233063\n",
            "1238.7147233486176\n",
            "1235.8655014038086\n",
            "1233.0065574645996\n",
            "1230.1383545398712\n",
            "1227.2606155872345\n",
            "1224.3738293647766\n",
            "1221.477707862854\n",
            "1218.5722887516022\n",
            "1215.6586525440216\n",
            "1212.7362234592438\n",
            "1209.8039855957031\n",
            "1206.8640456199646\n",
            "1203.915439605713\n",
            "1200.959138393402\n",
            "1197.994618654251\n",
            "1195.0214295387268\n",
            "1192.0409967899323\n",
            "1189.0521099567413\n",
            "1186.05708527565\n",
            "1183.0538799762726\n",
            "1180.0434262752533\n",
            "1177.026596546173\n",
            "1174.003509759903\n",
            "1170.9726254940033\n",
            "1167.9362647533417\n",
            "1164.8929333686829\n",
            "1161.8427386283875\n",
            "1158.7861218452454\n",
            "1155.7235918045044\n",
            "1152.6545996665955\n",
            "1149.5817286968231\n",
            "1146.5028936862946\n",
            "1143.4196064472198\n",
            "1140.330654144287\n",
            "1137.2367990016937\n",
            "1134.1392266750336\n",
            "1131.0365216732025\n",
            "1127.9297828674316\n",
            "1124.8189325332642\n",
            "1121.704107284546\n",
            "1118.585849761963\n",
            "1115.4641525745392\n",
            "1112.3384296894073\n",
            "1109.2101686000824\n",
            "1106.0783524513245\n",
            "1102.9437386989594\n",
            "1099.8064630031586\n",
            "1096.6659681797028\n",
            "1093.5231680870056\n",
            "1090.3780207633972\n",
            "1087.2314801216125\n",
            "1084.0837799310684\n",
            "1080.9338927268982\n",
            "1077.7838609218597\n",
            "1074.6322131156921\n",
            "1071.4809812307358\n",
            "1068.3282544612885\n",
            "1065.1757496595383\n",
            "1062.0233023166656\n",
            "1058.8719998598099\n",
            "1055.7221034765244\n",
            "1052.5726625919342\n",
            "1049.4252232313156\n",
            "1046.278069138527\n",
            "1043.1325019598007\n",
            "1039.9875925779343\n",
            "1036.845513701439\n",
            "1033.704566001892\n",
            "1030.5662709474564\n",
            "1027.4299938678741\n",
            "1024.295979499817\n",
            "1021.1640543937683\n",
            "1018.0358835458755\n",
            "1014.9092772006989\n",
            "1011.7874917984009\n",
            "1008.6691726446152\n",
            "1005.5540363788605\n",
            "1002.4441051483154\n",
            "999.338027715683\n",
            "996.2376059293747\n",
            "993.1421192884445\n",
            "990.0507253408432\n",
            "986.9646718502045\n",
            "983.8825962543488\n",
            "980.8071632385254\n",
            "977.736675620079\n",
            "974.6718304157257\n",
            "971.6128168106079\n",
            "968.5600950717926\n",
            "965.5133380889893\n",
            "962.473063826561\n",
            "959.4395880699158\n",
            "956.4124118089676\n",
            "953.3922805786133\n",
            "950.3792726993561\n",
            "947.3732645511627\n",
            "944.3755896091461\n",
            "941.3849741220474\n",
            "938.4022885560989\n",
            "935.4268683195114\n",
            "932.4604771137238\n",
            "929.5017635822296\n",
            "926.5508929491043\n",
            "923.6087175607681\n",
            "920.6751857995987\n",
            "917.750439286232\n",
            "914.8350201845169\n",
            "911.9289511442184\n",
            "909.0315263271332\n",
            "906.1434864997864\n",
            "903.2658516168594\n",
            "900.3975267410278\n",
            "897.5387288331985\n",
            "894.6897753477097\n",
            "891.8522815704346\n",
            "889.0228126049042\n",
            "886.2046639919281\n",
            "883.3967580795288\n",
            "880.5989768505096\n",
            "877.8127014636993\n",
            "875.0362857580185\n",
            "872.2703676223755\n",
            "869.5165038108826\n",
            "866.7731345891953\n",
            "864.0406947135925\n",
            "861.3185861110687\n",
            "858.6094918251038\n",
            "855.9099307060242\n",
            "853.2231863737106\n",
            "850.5462604761124\n",
            "847.8824174404144\n",
            "845.2292292118073\n",
            "842.5885338783264\n",
            "839.9591196775436\n",
            "837.3417432308197\n",
            "834.7358293533325\n",
            "832.1428778171539\n",
            "829.5626330375671\n",
            "826.9938161373138\n",
            "824.4382481575012\n",
            "821.8944226503372\n",
            "819.3620833158493\n",
            "816.8429865837097\n",
            "814.3360798358917\n",
            "811.8414494991302\n",
            "809.3592319488525\n",
            "806.8897303342819\n",
            "804.4328199625015\n",
            "801.9887034893036\n",
            "799.557143330574\n",
            "797.1376869678497\n",
            "794.7316726446152\n",
            "792.3377666473389\n",
            "789.9576778411865\n",
            "787.5887943506241\n",
            "785.2335827350616\n",
            "782.8906075954437\n",
            "780.5607092380524\n",
            "778.2438881397247\n",
            "775.9399762153625\n",
            "773.6480695009232\n",
            "771.370364189148\n",
            "769.1045759916306\n",
            "766.8518440723419\n",
            "764.6120216846466\n",
            "762.3845783472061\n",
            "760.1703894138336\n",
            "757.9685966968536\n",
            "755.7803653478622\n",
            "753.6048278808594\n",
            "751.4419665336609\n",
            "749.2914805412292\n",
            "747.1538039445877\n",
            "745.0300676822662\n",
            "742.9172683954239\n",
            "740.8178972005844\n",
            "738.7311384677887\n",
            "736.657230257988\n",
            "734.5959508419037\n",
            "732.5464760065079\n",
            "730.5104149580002\n",
            "728.4872425794601\n",
            "726.4761408567429\n",
            "724.4776413440704\n",
            "722.4915113449097\n",
            "720.5190826654434\n",
            "718.5585850477219\n",
            "716.6094888448715\n",
            "714.6746106147766\n",
            "712.7512464523315\n",
            "710.8409125804901\n",
            "708.941932797432\n",
            "707.0553071498871\n",
            "705.1815161705017\n",
            "703.3199409246445\n",
            "701.4706414937973\n",
            "699.6329272985458\n",
            "697.8082473278046\n",
            "695.9948222637177\n",
            "694.1937065124512\n",
            "692.4048988819122\n",
            "690.6271018981934\n",
            "688.8620526790619\n",
            "687.1081612110138\n",
            "685.3662778139114\n",
            "683.6362072229385\n",
            "681.9169646501541\n",
            "680.2107156515121\n",
            "678.5155034065247\n",
            "676.8318917751312\n",
            "675.1597851514816\n",
            "673.4991725683212\n",
            "671.8493491411209\n",
            "670.2115559577942\n",
            "668.5840849876404\n",
            "666.9690458774567\n",
            "665.3637787103653\n",
            "663.7707122564316\n",
            "662.1885929107666\n",
            "660.6183245182037\n",
            "659.0578404664993\n",
            "657.5087327957153\n",
            "655.9713162183762\n",
            "654.4438964128494\n",
            "652.9277149438858\n",
            "651.4215264320374\n",
            "649.9268877506256\n",
            "648.4422532320023\n",
            "646.9681137800217\n",
            "645.5046422481537\n",
            "644.0523415803909\n",
            "642.6096296310425\n",
            "641.1777100563049\n",
            "639.7556949853897\n",
            "638.3452924489975\n",
            "636.9430749416351\n",
            "635.5517911911011\n",
            "634.1712710857391\n",
            "632.8001186847687\n",
            "631.4382420778275\n",
            "630.0874544382095\n",
            "628.7462148666382\n",
            "627.4143862724304\n",
            "626.0925090312958\n",
            "624.7806218862534\n",
            "623.4777318239212\n",
            "622.1850440502167\n",
            "620.9009928703308\n",
            "619.6265649795532\n",
            "618.3617179393768\n",
            "617.1060875654221\n",
            "615.859312415123\n",
            "614.6224073171616\n",
            "613.393558382988\n",
            "612.1742880344391\n",
            "610.9648517370224\n",
            "609.7634444236755\n",
            "608.570415019989\n",
            "607.3871825933456\n",
            "606.2117557525635\n",
            "605.0458546876907\n",
            "603.8877038955688\n",
            "602.7380962371826\n",
            "601.5978059768677\n",
            "600.4650964736938\n",
            "599.341178894043\n",
            "598.224591255188\n",
            "597.1179095506668\n",
            "596.0177052021027\n",
            "594.9269150495529\n",
            "593.842965722084\n",
            "592.7683259248734\n",
            "591.7003664970398\n",
            "590.640590429306\n",
            "589.5889359712601\n",
            "588.5440580844879\n",
            "587.5085269212723\n",
            "586.4794191122055\n",
            "585.4584964513779\n",
            "584.4446613788605\n",
            "583.4384890794754\n",
            "582.4393792152405\n",
            "581.4478042125702\n",
            "580.4637221097946\n",
            "579.4868083000183\n",
            "578.5164868831635\n",
            "577.5539345741272\n",
            "576.5978888273239\n",
            "575.6489287614822\n",
            "574.7074583768845\n",
            "573.7730071544647\n",
            "572.8444181680679\n",
            "571.9227845668793\n",
            "571.0079588890076\n",
            "570.0998550653458\n",
            "569.1991214752197\n",
            "568.303982257843\n",
            "567.415909409523\n",
            "566.5340247154236\n",
            "565.6590665578842\n",
            "564.7902362346649\n",
            "563.9271665811539\n",
            "563.0714437961578\n",
            "562.2211363315582\n",
            "561.3775149583817\n",
            "560.5391924381256\n",
            "559.7080047130585\n",
            "558.882336974144\n",
            "558.0630493164062\n",
            "557.248896241188\n",
            "556.4412962198257\n",
            "555.6392525434494\n",
            "554.8435387611389\n",
            "554.0527191162109\n",
            "553.2693436145782\n",
            "552.4897688627243\n",
            "551.7171083688736\n",
            "550.9495919942856\n",
            "550.1880407333374\n",
            "549.430455327034\n",
            "548.6806048154831\n",
            "547.934863448143\n",
            "547.1940824985504\n",
            "546.459719657898\n",
            "545.7303646802902\n",
            "545.0063081979752\n",
            "544.2866374254227\n",
            "543.5734841823578\n",
            "542.8642946481705\n",
            "542.1610181331635\n",
            "541.4624373912811\n",
            "540.7679269313812\n",
            "540.0800570249557\n",
            "539.3958523273468\n",
            "538.7172658443451\n",
            "538.0437535047531\n",
            "537.374097943306\n",
            "536.709222316742\n",
            "536.0499913692474\n",
            "535.3950954675674\n",
            "534.7448099851608\n",
            "534.0990097522736\n",
            "533.4575663805008\n",
            "532.8209391832352\n",
            "532.1884783506393\n",
            "531.5608332157135\n",
            "530.937625169754\n",
            "530.3189322948456\n",
            "529.7032523155212\n",
            "529.0942162275314\n",
            "528.4867105484009\n",
            "527.885977268219\n",
            "527.2879512310028\n",
            "526.6947841644287\n",
            "526.1056253910065\n",
            "525.5202497243881\n",
            "524.9385973215103\n",
            "524.3624006509781\n",
            "523.7890591621399\n",
            "523.2191874980927\n",
            "522.6549463272095\n",
            "522.0929523706436\n",
            "521.5366051197052\n",
            "520.9816982746124\n",
            "520.432743191719\n",
            "519.8855353593826\n",
            "519.3445115089417\n",
            "518.8054351806641\n",
            "518.269854426384\n",
            "517.738974571228\n",
            "517.2114503383636\n",
            "516.6866329908371\n",
            "516.1670273542404\n",
            "515.6494081020355\n",
            "515.1360106468201\n",
            "514.6267684698105\n",
            "48\n",
            "stark\n",
            "85\n",
            "where\n",
            "132\n",
            "Maria\n",
            "57\n",
            "people\n",
            "145\n",
            "health\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "51rRcAZzDqDq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **In Detail**"
      ]
    },
    {
      "metadata": {
        "id": "0L7e6NopCkQV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*[pytorch library]* (https://github.com/pytorch/pytorch)\n",
        "\n",
        "*[pytorch tutorial]* (https://tutorials.pytorch.kr/beginner/nlp/word_embeddings_tutorial.html)"
      ]
    },
    {
      "metadata": {
        "id": "UFrDPnSMDGFq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1.  **Continuous Bag of Words_In Detail**"
      ]
    },
    {
      "metadata": {
        "id": "pnNv0_W1MdCv",
        "colab_type": "code",
        "outputId": "7c6059c7-0355-4174-b3bf-8280081fd824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "CONTEXT_SIZE = 3\n",
        "EMBEDDING_DIM = 10\n",
        "\n",
        "#string to list\n",
        "test_sentence = \"\"\"Empathy for the poor may not come easily to people who never experienced it. They may blame the victims and insist their predicament can be overcome through determination and hard work.\n",
        "But they may not realize that extreme poverty can be psychologically and physically incapacitating — a perpetual cycle of bad diets, health care and education exacerbated by the shaming and self-fulfilling prophecies that define it in the public imagination.\n",
        "Gordon Parks — perhaps more than any artist — saw poverty as “the most savage of all human afflictions” and realized the power of empathy to help us understand it. It was neither an abstract problem nor political symbol, but something he endured growing up destitute in rural Kansas and having spent years documenting poverty throughout the world, including the United States.\n",
        "That sensitivity informed “Freedom’s Fearful Foe: Poverty,” his celebrated photo essay published in Life magazine in June 1961. He took readers into the lives of a Brazilian boy, Flavio da Silva, and his family, who lived in the ramshackle Catacumba favela in the hills outside Rio de Janeiro. These stark photographs are the subject of a new book, “Gordon Parks: The Flavio Story” (Steidl/The Gordon Parks Foundation), which accompanies a traveling exhibition co-organized by the Ryerson Image Centre in Toronto, where it opens this week, and the J. Paul Getty Museum. Edited with texts by the exhibition’s co-curators, Paul Roth and Amanda Maddox, the book also includes a recent interview with Mr. da Silva and essays by Beatriz Jaguaribe, Maria Alice Rezende de Carvalho and Sérgio Burgi.\n",
        "\"\"\".split()\n",
        "print(test_sentence[0:10])\n",
        "print(\"test_sentence 길이: \",len(test_sentence),\", context_size 길이: \",CONTEXT_SIZE)\n",
        "print(\"i의 범위: 0부터 ~\", len(test_sentence)-CONTEXT_SIZE)\n",
        " \n",
        "CONTEXT_SIZE = 3\n",
        "ngrams = []\n",
        "for i in range(len(test_sentence) - CONTEXT_SIZE):\n",
        "    tup = [test_sentence[j] for j in np.arange(i , i + CONTEXT_SIZE) ]\n",
        "    ngrams.append((tup,test_sentence[i + CONTEXT_SIZE]))\n",
        "print(ngrams[:3])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Empathy', 'for', 'the', 'poor', 'may', 'not', 'come', 'easily', 'to', 'people']\n",
            "test_sentence 길이:  259 , context_size 길이:  3\n",
            "i의 범위: 0부터 ~ 256\n",
            "[(['Empathy', 'for', 'the'], 'poor'), (['for', 'the', 'poor'], 'may'), (['the', 'poor', 'may'], 'not')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lK4gTc5EMtAY",
        "colab_type": "code",
        "outputId": "818726f3-547c-4249-bbcd-88e2eeb5c86e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "#python에서의 set:중복제거 및 순서섞기\n",
        "vocab = set(test_sentence)\n",
        "print(\"Length of vocabulary\",len(vocab))\n",
        "#python에서의 dictionary:중복제거 및 순서섞기,pair유지\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "print(word_to_ix)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of vocabulary 195\n",
            "{'exacerbated': 0, 'most': 1, 'book,': 2, 'Foundation),': 3, 'neither': 4, 'this': 5, 'power': 6, 'essay': 7, 'Amanda': 8, 'Maria': 9, 'published': 10, 'an': 11, 'public': 12, 'political': 13, 'That': 14, 'Burgi.': 15, 'up': 16, 'cycle': 17, 'boy,': 18, 'savage': 19, 'shaming': 20, 'which': 21, 'Jaguaribe,': 22, 'determination': 23, 'poverty': 24, 'hills': 25, 'perpetual': 26, 'including': 27, 'co-curators,': 28, 'informed': 29, 'Empathy': 30, 'Paul': 31, 'Museum.': 32, 'artist': 33, 'includes': 34, 'Beatriz': 35, 'Life': 36, 'easily': 37, 'people': 38, 'more': 39, '“the': 40, 'Fearful': 41, 'diets,': 42, 'but': 43, 'photographs': 44, 'with': 45, 'in': 46, 'experienced': 47, 'help': 48, 'blame': 49, 'States.': 50, 'Maddox,': 51, 'Story”': 52, 'world,': 53, 'They': 54, 'through': 55, 'health': 56, 'Sérgio': 57, 'may': 58, 'J.': 59, 'be': 60, 'empathy': 61, 'It': 62, 'Gordon': 63, 'something': 64, 'ramshackle': 65, 'predicament': 66, 'stark': 67, 'rural': 68, 'of': 69, 'extreme': 70, 'a': 71, 'it': 72, 'imagination.': 73, 'accompanies': 74, 'realized': 75, 'Kansas': 76, 'photo': 77, 'book': 78, 'sensitivity': 79, 'celebrated': 80, 'any': 81, 'exhibition': 82, 'years': 83, 'problem': 84, 'endured': 85, 'and': 86, '“Freedom’s': 87, 'essays': 88, 'insist': 89, 'realize': 90, 'are': 91, 'took': 92, 'Catacumba': 93, 'opens': 94, 'he': 95, 'symbol,': 96, '“Gordon': 97, '—': 98, 'June': 99, 'Silva,': 100, 'into': 101, 'throughout': 102, 'victims': 103, 'destitute': 104, 'education': 105, 'exhibition’s': 106, 'The': 107, 'recent': 108, 'their': 109, 'having': 110, 'also': 111, 'as': 112, 'who': 113, 'Carvalho': 114, 'de': 115, 'incapacitating': 116, 'Roth': 117, 'work.': 118, 'spent': 119, 'Rio': 120, 'to': 121, 'self-fulfilling': 122, 'week,': 123, 'readers': 124, 'psychologically': 125, 'perhaps': 126, 'new': 127, 'co-organized': 128, 'lived': 129, 'outside': 130, 'come': 131, 'for': 132, 'These': 133, '(Steidl/The': 134, 'Image': 135, 'by': 136, 'us': 137, 'Silva': 138, 'Foe:': 139, 'prophecies': 140, 'they': 141, 'Ryerson': 142, 'human': 143, 'magazine': 144, 'Rezende': 145, 'bad': 146, 'that': 147, 'lives': 148, 'care': 149, 'He': 150, 'it.': 151, 'subject': 152, 'growing': 153, 'his': 154, 'favela': 155, 'all': 156, 'physically': 157, 'interview': 158, 'family,': 159, 'never': 160, 'nor': 161, 'Parks:': 162, 'not': 163, 'saw': 164, 'can': 165, 'But': 166, 'was': 167, 'understand': 168, 'Brazilian': 169, 'poor': 170, 'Getty': 171, 'hard': 172, 'Edited': 173, 'United': 174, 'Toronto,': 175, 'overcome': 176, 'da': 177, 'Alice': 178, 'traveling': 179, 'the': 180, 'Flavio': 181, 'Mr.': 182, 'texts': 183, 'afflictions”': 184, 'define': 185, 'documenting': 186, 'where': 187, 'Parks': 188, 'Janeiro.': 189, 'Poverty,”': 190, 'than': 191, '1961.': 192, 'abstract': 193, 'Centre': 194}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mSUa587jXQvR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![대체 텍스트](https://ljvmiranda921.github.io/assets/png/cs231n-ann/neg_log.png)"
      ]
    },
    {
      "metadata": {
        "id": "0sy8j-fcRr8c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "losses = []\n",
        "loss_function = nn.NLLLoss()\n",
        "model = CBOWModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W-nJ__RnW0Ms",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(len(vocab))\n",
        "print(model.forward(context_idxs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uzyXG6k3XoeC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "import sklearn\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "class CBOWModeler(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "        super(CBOWModeler, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim) #[195, 10]\n",
        "        self.linear1 = nn.Linear(context_size * embedding_dim, 128) #[30, 128]\n",
        "        self.linear2 = nn.Linear(128, vocab_size) #[128,195]\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs).view((1, -1))  # -1 implies size inferred for that index from the size of the data\n",
        "        #torch.Size([3, 10]) ----> torch.Size([1, 30])\n",
        "        #         print(np.mean(np.mean(self.linear2.weight.data.numpy())))\n",
        "        out1 = F.relu(self.linear1(embeds)) #[1,128]  # output of first layer \n",
        "        out2 = self.linear2(out1) #[1,195]   # output of second layer \n",
        "        log_probs = F.log_softmax(out2, dim=1)\n",
        "        return log_probs\n",
        "\n",
        "    def predict(self,input):\n",
        "        context_idxs = torch.tensor([word_to_ix[w] for w in input], dtype=torch.long) #input == ['of', 'all', 'human']\n",
        "        res = self.forward(context_idxs)\n",
        "        res_arg = torch.argmax(res) #tensor(184)\n",
        "        res_val, res_ind = res.sort(descending=True)\n",
        "        res_val = res_val[0][:3] #tensor([-0.0147, -5.5025, -6.0342])\n",
        "        res_ind = res_ind[0][:3] #tensor([83, 18,  7])\n",
        "#         for arg in zip(res_val,res_ind):\n",
        "            #print(arg)\n",
        "#             print([(key,val,arg[0]) for key,val in word_to_ix.items() if val == arg[1]]) \n",
        "              #[('afflictions”', 184, tensor(-0.0361, grad_fn=<SelectBackward>))]\n",
        "              #[('and', 86, tensor(-4.5022, grad_fn=<SelectBackward>))]\n",
        "              #[('Brazilian', 169, tensor(-5.9691, grad_fn=<SelectBackward>)]\n",
        "\n",
        "#     def freeze_layer(self,layer):\n",
        "#         for name,child in model.named_children():\n",
        "#             print(name,child)\n",
        "#             if(name == layer):\n",
        "#                 for names,params in child.named_parameters():\n",
        "#                     print(names,params)\n",
        "#                     print(params.size())\n",
        "#                     params.requires_grad= False\n",
        "\n",
        "    def print_layer_parameters(self):\n",
        "        for name,child in model.named_children():\n",
        "                print(name,child)\n",
        "                for names,params in child.named_parameters():\n",
        "                    print(names,params)\n",
        "                    print(params.size())\n",
        "\n",
        "    def write_embedding_to_file(self,filename):\n",
        "        for i in self.embeddings.parameters():\n",
        "            weights = i.data.numpy()\n",
        "        np.save(filename,weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hQMd0nUm6S-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "92969941-216d-48f4-b461-2d03a64add58"
      },
      "cell_type": "code",
      "source": [
        "for i in model.embeddings.parameters():\n",
        "  print(i.data.numpy())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.629781   -0.78158975 -0.6731153  ... -1.6852072  -0.7390124\n",
            "   0.3055563 ]\n",
            " [-0.80979836 -0.2985051  -0.22850177 ... -1.2276492   0.74952847\n",
            "   0.22642034]\n",
            " [ 0.8866281   0.26704207 -0.66539377 ... -1.4820443   0.03474152\n",
            "  -0.645877  ]\n",
            " ...\n",
            " [ 0.41772202 -0.15746632  1.4923147  ...  0.84195226  0.7695329\n",
            "   0.30093455]\n",
            " [-0.00277828  0.37276897  0.39554164 ...  0.61711174  0.5512562\n",
            "   0.46243757]\n",
            " [ 0.09873401 -1.653412   -0.33252206 ...  0.8537746  -1.0184102\n",
            "  -1.2885967 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v58ijfedlcVy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(400):\n",
        "    total_loss = 0\n",
        "    #------- Embedding layers are trained as well here ----#\n",
        "    #lookup_tensor = torch.tensor([word_to_ix[\"poor\"]], dtype=torch.long)\n",
        "    #hello_embed = model.embeddings(lookup_tensor)\n",
        "    #print(hello_embed)\n",
        "    # -----------------------------------------------------#\n",
        "\n",
        "    for context, target in ngrams:\n",
        "        #e.g.)context==[‘Empathy’,’for’,’the’], target==poor ...\n",
        "\n",
        "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
        "        # into integer indices and wrap them in tensors)\n",
        "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)        \n",
        "        #e.g.)context_idxs == Tensor([30,132,180])...\n",
        "\n",
        "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
        "        # new instance, you need to zero out the gradients from the old\n",
        "        # instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 3. Run the forward pass, getting log probabilities over next\n",
        "        # words\n",
        "        log_probs = model(context_idxs)\n",
        "#         print(log_probs)\n",
        "\n",
        "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
        "        # word wrapped in a tensor)\n",
        "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
        "        #print(loss)\n",
        "\n",
        "        # Step 5. Do the backward pass and update the gradient\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
        "        total_loss += loss.item()\n",
        "    print(total_loss)\n",
        "    losses.append(total_loss)\n",
        "#print(losses)  # The loss decreased every iteration over the training data!\n",
        "\n",
        "#Print the model layer parameters\n",
        "#model.print_layer_parameters()\n",
        "\n",
        "#Predict the next word given n context words\n",
        "model.predict(['of','all','human'])\n",
        "model.write_embedding_to_file('embeddings.npy')\n",
        "cluster_embeddings('embeddings.npy',2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "07uWggYtDO2w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2. **Skipgram_In Detail**"
      ]
    },
    {
      "metadata": {
        "id": "5F8CDS-wEK4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12695
        },
        "outputId": "012da107-7078-449f-93ec-71f3034cdefe"
      },
      "cell_type": "code",
      "source": [
        "#https://srijithr.gitlab.io/post/word2vec/\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "import sklearn\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "CONTEXT_SIZE = 3\n",
        "EMBEDDING_DIM = 10\n",
        "\n",
        "def get_key(word_id):\n",
        "    for key,val in word_to_ix.items():\n",
        "        if(val == word_id):\n",
        "            print(key)\n",
        "\n",
        "\n",
        "def cluster_embeddings(filename,nclusters):\n",
        "    X = np.load(filename)\n",
        "    kmeans = KMeans(n_clusters=nclusters, random_state=0).fit(X)\n",
        "    center = kmeans.cluster_centers_\n",
        "    distances = euclidean_distances(X,center)\n",
        "\n",
        "    for i in np.arange(0,distances.shape[1]):\n",
        "        word_id = np.argmin(distances[:,i])\n",
        "        print(word_id)\n",
        "        get_key(word_id)\n",
        "\n",
        "def read_data(file_path):\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    data = urllib.request.urlopen(file_path)\n",
        "    data = data.read().decode('utf8')\n",
        "    tokenized_data = word_tokenize(data)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    stop_words.update(['.',',',':',';','(',')','#','--','...','\"'])\n",
        "    cleaned_words = [ i for i in tokenized_data if i not in stop_words ]\n",
        "    return(cleaned_words)\n",
        "\n",
        "\n",
        "test_sentence = \"\"\"Empathy for the poor may not come easily to people who never experienced it. They may blame the victims and insist their predicament can be overcome through determination and hard work.\n",
        "But they may not realize that extreme poverty can be psychologically and physically incapacitating — a perpetual cycle of bad diets, health care and education exacerbated by the shaming and self-fulfilling prophecies that define it in the public imagination.\n",
        "Gordon Parks — perhaps more than any artist — saw poverty as “the most savage of all human afflictions” and realized the power of empathy to help us understand it. It was neither an abstract problem nor political symbol, but something he endured growing up destitute in rural Kansas and having spent years documenting poverty throughout the world, including the United States.\n",
        "That sensitivity informed “Freedom’s Fearful Foe: Poverty,” his celebrated photo essay published in Life magazine in June 1961. He took readers into the lives of a Brazilian boy, Flavio da Silva, and his family, who lived in the ramshackle Catacumba favela in the hills outside Rio de Janeiro. These stark photographs are the subject of a new book, “Gordon Parks: The Flavio Story” (Steidl/The Gordon Parks Foundation), which accompanies a traveling exhibition co-organized by the Ryerson Image Centre in Toronto, where it opens this week, and the J. Paul Getty Museum. Edited with texts by the exhibition’s co-curators, Paul Roth and Amanda Maddox, the book also includes a recent interview with Mr. da Silva and essays by Beatriz Jaguaribe, Maria Alice Rezende de Carvalho and Sérgio Burgi.\n",
        "\"\"\".split()\n",
        "# we should tokenize the input, but we will ignore that for now\n",
        "# build a list of tuples.  Each tuple is ([ word_i-2, word_i-1 ], target word)\n",
        "\n",
        "#test_sentence = read_data('https://www.gutenberg.org/files/57884/57884-0.txt')\n",
        "\n",
        "ngrams = []\n",
        "for i in range(len(test_sentence) - CONTEXT_SIZE):\n",
        "    tup = [test_sentence[j] for j in np.arange(i + 1 , i + CONTEXT_SIZE + 1) ]\n",
        "    ngrams.append((test_sentence[i],tup))\n",
        "# print the first 3, just so you can see what they look like\n",
        "#print(ngrams)\n",
        "\n",
        "\n",
        "vocab = set(test_sentence)\n",
        "print(\"Length of vocabulary\",len(vocab))\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "\n",
        "class SkipgramModeler(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "        super(SkipgramModeler, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim) #[195,10]\n",
        "        self.linear1 = nn.Linear(embedding_dim, 128) #[10,128]\n",
        "        self.linear2 = nn.Linear(128, context_size * vocab_size) #[128,3*195=585]\n",
        "        #self.parameters['context_size'] = context_size\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs).view((1, -1))  # -1 implies size inferred for that index from the size of the data #[1,10]\n",
        "        #print(np.mean(np.mean(self.linear2.weight.data.numpy())))\n",
        "        out1 = F.relu(self.linear1(embeds)) # output of first layer #[1,128]\n",
        "        out2 = self.linear2(out1)# output of second [1,585]\n",
        "        log_probs = F.log_softmax(out2, dim=1).view(CONTEXT_SIZE,-1)  #[3,195]\n",
        "        return log_probs\n",
        "\n",
        "    def predict(self,input): #input=='psychologically'\n",
        "        context_idxs = torch.tensor([word_to_ix[input]], dtype=torch.long) # tensor([125])\n",
        "        res = self.forward(context_idxs)\n",
        "        res_arg = torch.argmax(res)\n",
        "        res_val, res_ind = res.sort(descending=True)\n",
        "        indices = [res_ind[i][0] for i in np.arange(0,3)]\n",
        "#         print(indices) e.g.)[tensor(77), tensor(37), tensor(158)]        \n",
        "#         for arg in indices:\n",
        "#             print( [ (key, val) for key,val in word_to_ix.items() if val == arg ])    #[(‘people’,77)][(‘their’,37)][(‘a’,158)]\n",
        "\n",
        "\n",
        "#     def freeze_layer(self,layer):\n",
        "#         for name,child in model.named_children():\n",
        "#             print(name,child)\n",
        "#             if(name == layer):\n",
        "#                 for names,params in child.named_parameters():\n",
        "#                     print(names,params)\n",
        "#                     print(params.size())\n",
        "#                     params.requires_grad= False\n",
        "\n",
        "    def print_layer_parameters(self):\n",
        "        for name,child in model.named_children():\n",
        "                print(name,child)\n",
        "                for names,params in child.named_parameters():\n",
        "                    print(names,params)\n",
        "                    print(params.size())\n",
        "\n",
        "    def write_embedding_to_file(self,filename):\n",
        "        for i in self.embeddings.parameters():\n",
        "            weights = i.data.numpy()\n",
        "        np.save(filename,weights)\n",
        "\n",
        "\n",
        "losses = []\n",
        "loss_function = nn.NLLLoss()\n",
        "model = SkipgramModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "# Freeze embedding layer\n",
        "#model.freeze_layer('embeddings')\n",
        "\n",
        "for epoch in range(550):\n",
        "    total_loss = 0\n",
        "    #------- Embedding layers are trained as well here ----#\n",
        "    #lookup_tensor = torch.tensor([word_to_ix[\"poor\"]], dtype=torch.long)\n",
        "    #hello_embed = model.embeddings(lookup_tensor)\n",
        "    #print(hello_embed)\n",
        "    # -----------------------------------------------------#\n",
        "\n",
        "    model.predict('psychologically')\n",
        "\n",
        "    for context, target in ngrams:\n",
        "\n",
        "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
        "        # into integer indices and wrap them in tensors) \n",
        "#         print(context,target) e.g.)context == Empathy, target == ['for', 'the', 'poor']\n",
        "\n",
        "        context_idxs = torch.tensor([word_to_ix[context]], dtype=torch.long)\n",
        "#         print(\"Context id\",context_idxs) # Context id tensor([42])\n",
        "\n",
        "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
        "        # new instance, you need to zero out the gradients from the old\n",
        "        # instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 3. Run the forward pass, getting log probabilities over next\n",
        "        # words\n",
        "        log_probs = model(context_idxs)\n",
        "#         print(log_probs)\n",
        "\n",
        "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
        "        # word wrapped in a tensor)\n",
        "        target_list = torch.tensor([word_to_ix[w] for w in target], dtype=torch.long) #e.g.) tensor([192, 180,  67])\n",
        "        loss = loss_function(log_probs, target_list)\n",
        "#         print(loss)\n",
        "\n",
        "        # Step 5. Do the backward pass and update the gradient\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
        "        total_loss += loss.item()\n",
        "    print(total_loss)\n",
        "    losses.append(total_loss)\n",
        "#print(losses)  # The loss decreased every iteration over the training data!\n",
        "\n",
        "# Print the model layer parameters\n",
        "print(model.print_layer_parameters())\n",
        "\n",
        "#Predict the next word given n context words\n",
        "model.predict('psychologically')\n",
        "model.write_embedding_to_file('embeddings_skipgrams.npy')\n",
        "cluster_embeddings('embeddings_skipgrams.npy',5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of vocabulary 195\n",
            "1638.4615502357483\n",
            "1635.9240007400513\n",
            "1633.403148651123\n",
            "1630.8984184265137\n",
            "1628.4083499908447\n",
            "1625.9311332702637\n",
            "1623.4669008255005\n",
            "1621.0151329040527\n",
            "1618.5751128196716\n",
            "1616.1457662582397\n",
            "1613.7263226509094\n",
            "1611.315972328186\n",
            "1608.9144911766052\n",
            "1606.5211324691772\n",
            "1604.1355395317078\n",
            "1601.7573890686035\n",
            "1599.385597229004\n",
            "1597.0204801559448\n",
            "1594.661952972412\n",
            "1592.309163570404\n",
            "1589.9618310928345\n",
            "1587.6193866729736\n",
            "1585.2817578315735\n",
            "1582.9486985206604\n",
            "1580.6201753616333\n",
            "1578.296314239502\n",
            "1575.9768886566162\n",
            "1573.6614785194397\n",
            "1571.3503098487854\n",
            "1569.0439100265503\n",
            "1566.7426753044128\n",
            "1564.4461741447449\n",
            "1562.1548705101013\n",
            "1559.8684539794922\n",
            "1557.5869545936584\n",
            "1555.310601234436\n",
            "1553.0399689674377\n",
            "1550.7757172584534\n",
            "1548.5182428359985\n",
            "1546.2681169509888\n",
            "1544.0264735221863\n",
            "1541.7934303283691\n",
            "1539.568899154663\n",
            "1537.353190422058\n",
            "1535.1466813087463\n",
            "1532.9497385025024\n",
            "1530.7628536224365\n",
            "1528.58642911911\n",
            "1526.4202723503113\n",
            "1524.264654636383\n",
            "1522.1196756362915\n",
            "1519.9856386184692\n",
            "1517.8626103401184\n",
            "1515.7503690719604\n",
            "1513.6491436958313\n",
            "1511.5582432746887\n",
            "1509.4779815673828\n",
            "1507.4074659347534\n",
            "1505.3470830917358\n",
            "1503.296944618225\n",
            "1501.2552590370178\n",
            "1499.2224340438843\n",
            "1497.1984281539917\n",
            "1495.182207107544\n",
            "1493.1728286743164\n",
            "1491.169755935669\n",
            "1489.1724615097046\n",
            "1487.1805033683777\n",
            "1485.1938276290894\n",
            "1483.2113614082336\n",
            "1481.2315015792847\n",
            "1479.2534823417664\n",
            "1477.277973651886\n",
            "1475.3034181594849\n",
            "1473.3295180797577\n",
            "1471.3555212020874\n",
            "1469.3815650939941\n",
            "1467.407166004181\n",
            "1465.4305646419525\n",
            "1463.452109336853\n",
            "1461.4716613292694\n",
            "1459.4888129234314\n",
            "1457.5031154155731\n",
            "1455.5138761997223\n",
            "1453.5201833248138\n",
            "1451.522748708725\n",
            "1449.5209381580353\n",
            "1447.514122724533\n",
            "1445.501930475235\n",
            "1443.4836637973785\n",
            "1441.4588613510132\n",
            "1439.4281487464905\n",
            "1437.3915672302246\n",
            "1435.3483211994171\n",
            "1433.2982428073883\n",
            "1431.2419910430908\n",
            "1429.1783957481384\n",
            "1427.106858253479\n",
            "1425.0275688171387\n",
            "1422.9405589103699\n",
            "1420.8457579612732\n",
            "1418.742335319519\n",
            "1416.630755186081\n",
            "1414.5098078250885\n",
            "1412.3811733722687\n",
            "1410.2438986301422\n",
            "1408.0978753566742\n",
            "1405.9429404735565\n",
            "1403.7788047790527\n",
            "1401.606455564499\n",
            "1399.4242460727692\n",
            "1397.2330935001373\n",
            "1395.03271484375\n",
            "1392.8227632045746\n",
            "1390.6036486625671\n",
            "1388.3749396800995\n",
            "1386.1364829540253\n",
            "1383.8886063098907\n",
            "1381.6314988136292\n",
            "1379.364895582199\n",
            "1377.0885000228882\n",
            "1374.8018140792847\n",
            "1372.505436182022\n",
            "1370.1994705200195\n",
            "1367.8832652568817\n",
            "1365.5571854114532\n",
            "1363.220627784729\n",
            "1360.874766588211\n",
            "1358.518410205841\n",
            "1356.1519358158112\n",
            "1353.7753715515137\n",
            "1351.3878092765808\n",
            "1348.991250038147\n",
            "1346.5833132266998\n",
            "1344.165545463562\n",
            "1341.7365732192993\n",
            "1339.298088312149\n",
            "1336.8481245040894\n",
            "1334.388123512268\n",
            "1331.917509317398\n",
            "1329.4364292621613\n",
            "1326.9446332454681\n",
            "1324.4422054290771\n",
            "1321.9289102554321\n",
            "1319.404770374298\n",
            "1316.8699996471405\n",
            "1314.3239707946777\n",
            "1311.7677431106567\n",
            "1309.2008004188538\n",
            "1306.622540473938\n",
            "1304.0341720581055\n",
            "1301.4336035251617\n",
            "1298.823261499405\n",
            "1296.2023856639862\n",
            "1293.56995511055\n",
            "1290.9260430335999\n",
            "1288.272804737091\n",
            "1285.6081602573395\n",
            "1282.9318289756775\n",
            "1280.24569106102\n",
            "1277.5483829975128\n",
            "1274.8410651683807\n",
            "1272.123356103897\n",
            "1269.395750284195\n",
            "1266.657126903534\n",
            "1263.9088199138641\n",
            "1261.150262594223\n",
            "1258.3813922405243\n",
            "1255.6021370887756\n",
            "1252.8129301071167\n",
            "1250.0129129886627\n",
            "1247.2037107944489\n",
            "1244.383245229721\n",
            "1241.5542166233063\n",
            "1238.7147233486176\n",
            "1235.8655014038086\n",
            "1233.0065574645996\n",
            "1230.1383545398712\n",
            "1227.2606155872345\n",
            "1224.3738293647766\n",
            "1221.477707862854\n",
            "1218.5722887516022\n",
            "1215.6586525440216\n",
            "1212.7362234592438\n",
            "1209.8039855957031\n",
            "1206.8640456199646\n",
            "1203.915439605713\n",
            "1200.959138393402\n",
            "1197.994618654251\n",
            "1195.0214295387268\n",
            "1192.0409967899323\n",
            "1189.0521099567413\n",
            "1186.05708527565\n",
            "1183.0538799762726\n",
            "1180.0434262752533\n",
            "1177.026596546173\n",
            "1174.003509759903\n",
            "1170.9726254940033\n",
            "1167.9362647533417\n",
            "1164.8929333686829\n",
            "1161.8427386283875\n",
            "1158.7861218452454\n",
            "1155.7235918045044\n",
            "1152.6545996665955\n",
            "1149.5817286968231\n",
            "1146.5028936862946\n",
            "1143.4196064472198\n",
            "1140.330654144287\n",
            "1137.2367990016937\n",
            "1134.1392266750336\n",
            "1131.0365216732025\n",
            "1127.9297828674316\n",
            "1124.8189325332642\n",
            "1121.704107284546\n",
            "1118.585849761963\n",
            "1115.4641525745392\n",
            "1112.3384296894073\n",
            "1109.2101686000824\n",
            "1106.0783524513245\n",
            "1102.9437386989594\n",
            "1099.8064630031586\n",
            "1096.6659681797028\n",
            "1093.5231680870056\n",
            "1090.3780207633972\n",
            "1087.2314801216125\n",
            "1084.0837799310684\n",
            "1080.9338927268982\n",
            "1077.7838609218597\n",
            "1074.6322131156921\n",
            "1071.4809812307358\n",
            "1068.3282544612885\n",
            "1065.1757496595383\n",
            "1062.0233023166656\n",
            "1058.8719998598099\n",
            "1055.7221034765244\n",
            "1052.5726625919342\n",
            "1049.4252232313156\n",
            "1046.278069138527\n",
            "1043.1325019598007\n",
            "1039.9875925779343\n",
            "1036.845513701439\n",
            "1033.704566001892\n",
            "1030.5662709474564\n",
            "1027.4299938678741\n",
            "1024.295979499817\n",
            "1021.1640543937683\n",
            "1018.0358835458755\n",
            "1014.9092772006989\n",
            "1011.7874917984009\n",
            "1008.6691726446152\n",
            "1005.5540363788605\n",
            "1002.4441051483154\n",
            "999.338027715683\n",
            "996.2376059293747\n",
            "993.1421192884445\n",
            "990.0507253408432\n",
            "986.9646718502045\n",
            "983.8825962543488\n",
            "980.8071632385254\n",
            "977.736675620079\n",
            "974.6718304157257\n",
            "971.6128168106079\n",
            "968.5600950717926\n",
            "965.5133380889893\n",
            "962.473063826561\n",
            "959.4395880699158\n",
            "956.4124118089676\n",
            "953.3922805786133\n",
            "950.3792726993561\n",
            "947.3732645511627\n",
            "944.3755896091461\n",
            "941.3849741220474\n",
            "938.4022885560989\n",
            "935.4268683195114\n",
            "932.4604771137238\n",
            "929.5017635822296\n",
            "926.5508929491043\n",
            "923.6087175607681\n",
            "920.6751857995987\n",
            "917.750439286232\n",
            "914.8350201845169\n",
            "911.9289511442184\n",
            "909.0315263271332\n",
            "906.1434864997864\n",
            "903.2658516168594\n",
            "900.3975267410278\n",
            "897.5387288331985\n",
            "894.6897753477097\n",
            "891.8522815704346\n",
            "889.0228126049042\n",
            "886.2046639919281\n",
            "883.3967580795288\n",
            "880.5989768505096\n",
            "877.8127014636993\n",
            "875.0362857580185\n",
            "872.2703676223755\n",
            "869.5165038108826\n",
            "866.7731345891953\n",
            "864.0406947135925\n",
            "861.3185861110687\n",
            "858.6094918251038\n",
            "855.9099307060242\n",
            "853.2231863737106\n",
            "850.5462604761124\n",
            "847.8824174404144\n",
            "845.2292292118073\n",
            "842.5885338783264\n",
            "839.9591196775436\n",
            "837.3417432308197\n",
            "834.7358293533325\n",
            "832.1428778171539\n",
            "829.5626330375671\n",
            "826.9938161373138\n",
            "824.4382481575012\n",
            "821.8944226503372\n",
            "819.3620833158493\n",
            "816.8429865837097\n",
            "814.3360798358917\n",
            "811.8414494991302\n",
            "809.3592319488525\n",
            "806.8897303342819\n",
            "804.4328199625015\n",
            "801.9887034893036\n",
            "799.557143330574\n",
            "797.1376869678497\n",
            "794.7316726446152\n",
            "792.3377666473389\n",
            "789.9576778411865\n",
            "787.5887943506241\n",
            "785.2335827350616\n",
            "782.8906075954437\n",
            "780.5607092380524\n",
            "778.2438881397247\n",
            "775.9399762153625\n",
            "773.6480695009232\n",
            "771.370364189148\n",
            "769.1045759916306\n",
            "766.8518440723419\n",
            "764.6120216846466\n",
            "762.3845783472061\n",
            "760.1703894138336\n",
            "757.9685966968536\n",
            "755.7803653478622\n",
            "753.6048278808594\n",
            "751.4419665336609\n",
            "749.2914805412292\n",
            "747.1538039445877\n",
            "745.0300676822662\n",
            "742.9172683954239\n",
            "740.8178972005844\n",
            "738.7311384677887\n",
            "736.657230257988\n",
            "734.5959508419037\n",
            "732.5464760065079\n",
            "730.5104149580002\n",
            "728.4872425794601\n",
            "726.4761408567429\n",
            "724.4776413440704\n",
            "722.4915113449097\n",
            "720.5190826654434\n",
            "718.5585850477219\n",
            "716.6094888448715\n",
            "714.6746106147766\n",
            "712.7512464523315\n",
            "710.8409125804901\n",
            "708.941932797432\n",
            "707.0553071498871\n",
            "705.1815161705017\n",
            "703.3199409246445\n",
            "701.4706414937973\n",
            "699.6329272985458\n",
            "697.8082473278046\n",
            "695.9948222637177\n",
            "694.1937065124512\n",
            "692.4048988819122\n",
            "690.6271018981934\n",
            "688.8620526790619\n",
            "687.1081612110138\n",
            "685.3662778139114\n",
            "683.6362072229385\n",
            "681.9169646501541\n",
            "680.2107156515121\n",
            "678.5155034065247\n",
            "676.8318917751312\n",
            "675.1597851514816\n",
            "673.4991725683212\n",
            "671.8493491411209\n",
            "670.2115559577942\n",
            "668.5840849876404\n",
            "666.9690458774567\n",
            "665.3637787103653\n",
            "663.7707122564316\n",
            "662.1885929107666\n",
            "660.6183245182037\n",
            "659.0578404664993\n",
            "657.5087327957153\n",
            "655.9713162183762\n",
            "654.4438964128494\n",
            "652.9277149438858\n",
            "651.4215264320374\n",
            "649.9268877506256\n",
            "648.4422532320023\n",
            "646.9681137800217\n",
            "645.5046422481537\n",
            "644.0523415803909\n",
            "642.6096296310425\n",
            "641.1777100563049\n",
            "639.7556949853897\n",
            "638.3452924489975\n",
            "636.9430749416351\n",
            "635.5517911911011\n",
            "634.1712710857391\n",
            "632.8001186847687\n",
            "631.4382420778275\n",
            "630.0874544382095\n",
            "628.7462148666382\n",
            "627.4143862724304\n",
            "626.0925090312958\n",
            "624.7806218862534\n",
            "623.4777318239212\n",
            "622.1850440502167\n",
            "620.9009928703308\n",
            "619.6265649795532\n",
            "618.3617179393768\n",
            "617.1060875654221\n",
            "615.859312415123\n",
            "614.6224073171616\n",
            "613.393558382988\n",
            "612.1742880344391\n",
            "610.9648517370224\n",
            "609.7634444236755\n",
            "608.570415019989\n",
            "607.3871825933456\n",
            "606.2117557525635\n",
            "605.0458546876907\n",
            "603.8877038955688\n",
            "602.7380962371826\n",
            "601.5978059768677\n",
            "600.4650964736938\n",
            "599.341178894043\n",
            "598.224591255188\n",
            "597.1179095506668\n",
            "596.0177052021027\n",
            "594.9269150495529\n",
            "593.842965722084\n",
            "592.7683259248734\n",
            "591.7003664970398\n",
            "590.640590429306\n",
            "589.5889359712601\n",
            "588.5440580844879\n",
            "587.5085269212723\n",
            "586.4794191122055\n",
            "585.4584964513779\n",
            "584.4446613788605\n",
            "583.4384890794754\n",
            "582.4393792152405\n",
            "581.4478042125702\n",
            "580.4637221097946\n",
            "579.4868083000183\n",
            "578.5164868831635\n",
            "577.5539345741272\n",
            "576.5978888273239\n",
            "575.6489287614822\n",
            "574.7074583768845\n",
            "573.7730071544647\n",
            "572.8444181680679\n",
            "571.9227845668793\n",
            "571.0079588890076\n",
            "570.0998550653458\n",
            "569.1991214752197\n",
            "568.303982257843\n",
            "567.415909409523\n",
            "566.5340247154236\n",
            "565.6590665578842\n",
            "564.7902362346649\n",
            "563.9271665811539\n",
            "563.0714437961578\n",
            "562.2211363315582\n",
            "561.3775149583817\n",
            "560.5391924381256\n",
            "559.7080047130585\n",
            "558.882336974144\n",
            "558.0630493164062\n",
            "557.248896241188\n",
            "556.4412962198257\n",
            "555.6392525434494\n",
            "554.8435387611389\n",
            "554.0527191162109\n",
            "553.2693436145782\n",
            "552.4897688627243\n",
            "551.7171083688736\n",
            "550.9495919942856\n",
            "550.1880407333374\n",
            "549.430455327034\n",
            "548.6806048154831\n",
            "547.934863448143\n",
            "547.1940824985504\n",
            "546.459719657898\n",
            "545.7303646802902\n",
            "545.0063081979752\n",
            "544.2866374254227\n",
            "543.5734841823578\n",
            "542.8642946481705\n",
            "542.1610181331635\n",
            "541.4624373912811\n",
            "540.7679269313812\n",
            "540.0800570249557\n",
            "539.3958523273468\n",
            "538.7172658443451\n",
            "538.0437535047531\n",
            "537.374097943306\n",
            "536.709222316742\n",
            "536.0499913692474\n",
            "535.3950954675674\n",
            "534.7448099851608\n",
            "534.0990097522736\n",
            "533.4575663805008\n",
            "532.8209391832352\n",
            "532.1884783506393\n",
            "531.5608332157135\n",
            "530.937625169754\n",
            "530.3189322948456\n",
            "529.7032523155212\n",
            "529.0942162275314\n",
            "528.4867105484009\n",
            "527.885977268219\n",
            "527.2879512310028\n",
            "526.6947841644287\n",
            "526.1056253910065\n",
            "525.5202497243881\n",
            "524.9385973215103\n",
            "524.3624006509781\n",
            "523.7890591621399\n",
            "523.2191874980927\n",
            "522.6549463272095\n",
            "522.0929523706436\n",
            "521.5366051197052\n",
            "520.9816982746124\n",
            "520.432743191719\n",
            "519.8855353593826\n",
            "519.3445115089417\n",
            "518.8054351806641\n",
            "518.269854426384\n",
            "517.738974571228\n",
            "517.2114503383636\n",
            "516.6866329908371\n",
            "516.1670273542404\n",
            "515.6494081020355\n",
            "515.1360106468201\n",
            "514.6267684698105\n",
            "embeddings Embedding(195, 10)\n",
            "weight Parameter containing:\n",
            "tensor([[-1.6095, -0.8277, -0.7385,  ..., -1.7104, -0.7587,  0.2963],\n",
            "        [-0.8669, -0.2160, -0.2912,  ..., -1.2854,  0.7584,  0.2209],\n",
            "        [ 0.8464,  0.2404, -0.5693,  ..., -1.6472,  0.1284, -0.6738],\n",
            "        ...,\n",
            "        [ 0.4271, -0.2239,  1.5210,  ...,  0.9141,  0.9089,  0.4294],\n",
            "        [ 0.0350,  0.4175,  0.4954,  ...,  0.5155,  0.5927,  0.5673],\n",
            "        [ 0.0090, -1.6608, -0.3798,  ...,  0.9937, -1.1331, -1.4916]],\n",
            "       requires_grad=True)\n",
            "torch.Size([195, 10])\n",
            "linear1 Linear(in_features=10, out_features=128, bias=True)\n",
            "weight Parameter containing:\n",
            "tensor([[ 0.1094,  0.3231,  0.1998,  ...,  0.3806,  0.1181, -0.0724],\n",
            "        [ 0.4161,  0.6046,  0.1786,  ..., -0.5665, -0.5257, -0.9198],\n",
            "        [ 0.5608,  0.8200,  0.4663,  ..., -0.2878, -0.3903,  0.7810],\n",
            "        ...,\n",
            "        [-0.7014, -0.2485,  0.9427,  ..., -0.3509,  0.4189,  0.0165],\n",
            "        [-0.2079, -0.4191, -0.1045,  ..., -0.0802,  0.3168, -0.6523],\n",
            "        [ 0.0247,  0.8882, -0.0026,  ...,  0.3237, -0.3656,  0.6322]],\n",
            "       requires_grad=True)\n",
            "torch.Size([128, 10])\n",
            "bias Parameter containing:\n",
            "tensor([-0.1385,  0.7066,  0.0312,  0.1422,  0.5794,  0.2413,  0.4707,  0.0999,\n",
            "         0.2801,  0.4946,  0.5793,  0.4321,  0.2563,  0.4575,  0.5289,  0.4264,\n",
            "         0.2299,  0.4209,  0.9397, -0.0588,  0.0784,  0.2703,  0.5879,  0.0391,\n",
            "         0.1619,  0.1108,  0.3411,  0.1468,  0.4578,  0.7474,  0.5751, -0.1128,\n",
            "         0.1805,  0.8280,  0.5384,  0.8008,  0.6340,  0.3480,  0.8032,  0.8947,\n",
            "         0.6391,  0.1923,  0.6716,  0.9324,  0.1034,  0.8295,  0.0087,  0.4925,\n",
            "         0.0941,  0.2395,  0.4149,  0.2831,  0.1516,  0.7000,  0.0176,  0.5740,\n",
            "         0.1892,  0.5383,  0.2229,  0.0256,  0.3607,  0.1732,  0.3255,  0.4148,\n",
            "        -0.1242,  0.5188,  0.6578,  0.0558,  0.2313,  0.8233,  0.0105,  1.0104,\n",
            "        -0.1406,  0.4297,  0.5932,  0.1903, -0.0620, -0.0371,  0.1773,  0.1451,\n",
            "         0.3851,  0.7291,  0.3118,  0.6321, -0.0937,  0.2634,  0.8463,  0.8443,\n",
            "         0.5856,  0.3295,  0.1206,  0.6223,  0.1775,  0.5101, -0.0773,  0.1857,\n",
            "         0.2330,  0.3712,  0.4317,  0.2675,  0.6773,  0.5107,  0.8538,  0.4611,\n",
            "        -0.0257,  0.2547,  0.7348,  0.2177,  0.3389,  0.6879,  0.0615,  1.0592,\n",
            "         0.1433,  0.4211, -0.0360,  0.0612,  0.1098,  0.6209,  0.9461, -0.1182,\n",
            "         0.1203,  0.7286,  0.2797,  0.9693,  0.2051,  0.3417, -0.1195,  0.3246],\n",
            "       requires_grad=True)\n",
            "torch.Size([128])\n",
            "linear2 Linear(in_features=128, out_features=585, bias=True)\n",
            "weight Parameter containing:\n",
            "tensor([[ 0.0438, -0.0412, -0.1174,  ...,  0.0226,  0.0492,  0.0434],\n",
            "        [-0.0720,  0.0548,  0.1092,  ..., -0.0210,  0.0038,  0.0638],\n",
            "        [ 0.0164, -0.0926,  0.0566,  ..., -0.0178,  0.0155, -0.0736],\n",
            "        ...,\n",
            "        [ 0.0214, -0.0091,  0.0344,  ..., -0.0499,  0.0434,  0.0994],\n",
            "        [-0.0989,  0.0561,  0.0100,  ...,  0.0477, -0.0602,  0.0145],\n",
            "        [ 0.1440,  0.0499,  0.0894,  ...,  0.1188, -0.0316,  0.0486]],\n",
            "       requires_grad=True)\n",
            "torch.Size([585, 128])\n",
            "bias Parameter containing:\n",
            "tensor([-1.3691e-02, -5.3412e-03,  4.8271e-02, -4.8087e-02,  9.5844e-02,\n",
            "         5.6795e-02,  7.0262e-02,  8.0449e-02, -9.7394e-03, -8.2662e-02,\n",
            "        -4.7993e-02, -1.8666e-03,  3.8278e-02, -4.3083e-02,  1.3943e-03,\n",
            "         3.7728e-02, -9.2948e-03, -7.5303e-02, -1.1158e-01, -1.1102e-01,\n",
            "        -5.6783e-02,  7.9117e-02,  1.2754e-02,  1.3652e-01, -6.6976e-02,\n",
            "        -1.6380e-02, -2.6031e-02,  1.7496e-01, -4.6719e-02, -9.3246e-02,\n",
            "        -7.7645e-02,  2.5604e-02, -3.9509e-02,  1.0637e-01,  4.9964e-02,\n",
            "         1.2551e-01, -9.2411e-02,  6.9312e-02, -3.7983e-02, -5.6300e-02,\n",
            "         7.6607e-02, -9.8771e-02,  3.3992e-02, -2.6931e-02, -5.2311e-02,\n",
            "        -1.0551e-01, -8.8999e-02,  6.0007e-02, -1.0090e-01,  2.7415e-03,\n",
            "        -3.0576e-02, -5.2834e-02,  8.5218e-02, -4.1329e-02, -2.6236e-02,\n",
            "         1.4725e-01,  7.9194e-02,  1.4350e-03, -7.5487e-02,  1.3935e-02,\n",
            "         1.3011e-02,  4.9570e-02, -9.8526e-03,  6.3755e-02, -2.5983e-02,\n",
            "        -7.5485e-02, -5.5271e-02,  7.6876e-02,  1.4303e-01, -4.9624e-04,\n",
            "        -3.2854e-02, -8.7064e-02, -9.7203e-02,  1.6257e-02, -1.3101e-02,\n",
            "        -2.1218e-02,  4.9927e-02, -7.3333e-02, -1.0060e-01,  7.1936e-02,\n",
            "         6.1255e-02, -2.1088e-02, -4.3917e-02, -1.1308e-01,  1.2884e-02,\n",
            "        -1.4007e-01, -5.7273e-02,  2.2993e-02,  4.4973e-02, -3.5934e-02,\n",
            "         2.1418e-02,  1.5542e-03,  9.4199e-05,  7.1879e-03,  4.8307e-02,\n",
            "         1.0286e-01, -9.3528e-03, -6.4404e-02, -4.9610e-02, -1.5615e-02,\n",
            "         1.6646e-02,  3.2307e-02,  9.5508e-02,  8.4811e-02, -5.0272e-02,\n",
            "         1.6613e-02, -9.8516e-02, -4.8212e-02,  2.0964e-02,  1.1941e-02,\n",
            "         4.7729e-03, -2.4297e-02, -5.2907e-02,  9.0746e-04,  6.6387e-02,\n",
            "         2.1979e-02,  2.0268e-02,  5.7284e-02,  3.9939e-02, -4.3626e-02,\n",
            "         9.1798e-02, -1.9022e-02,  3.3038e-02,  3.8142e-02,  3.2462e-02,\n",
            "         1.1392e-02, -2.4399e-03, -1.7143e-02, -7.8370e-02,  6.3990e-02,\n",
            "        -7.6673e-03,  6.8564e-04, -6.6323e-02, -4.0179e-02,  6.3988e-02,\n",
            "         9.3909e-02, -7.5666e-02,  5.7269e-03,  2.6386e-02,  2.5816e-02,\n",
            "        -3.3776e-02, -1.1942e-01,  6.6007e-02, -9.7537e-02, -7.0897e-02,\n",
            "         5.4244e-02,  7.7942e-03, -1.5667e-02, -9.6992e-02, -1.0214e-01,\n",
            "         8.3283e-02, -7.5849e-02,  4.8502e-02, -8.9980e-02, -4.1949e-02,\n",
            "        -5.5417e-02, -4.3844e-02, -7.5504e-02,  2.8205e-02,  3.5717e-02,\n",
            "        -3.1322e-02, -4.5224e-02,  1.4622e-02,  9.2451e-02,  2.4288e-02,\n",
            "        -5.7815e-02, -4.6476e-02, -3.4169e-02, -5.6683e-02, -5.0830e-04,\n",
            "        -5.5648e-02, -6.9793e-02, -6.0051e-02,  8.8658e-02, -1.8487e-02,\n",
            "        -8.0522e-02,  4.9501e-02,  1.0104e-01,  4.3423e-02,  5.2623e-02,\n",
            "        -8.5695e-02, -5.6550e-02, -9.4767e-02,  9.8739e-03,  5.9118e-02,\n",
            "         5.8258e-02,  2.5535e-01,  5.2735e-02,  6.5216e-02, -2.0717e-03,\n",
            "         2.1125e-01, -8.1779e-02,  7.9078e-02, -6.7450e-02, -5.9965e-02,\n",
            "         2.3070e-03, -7.6595e-02,  2.4857e-02, -3.7828e-02,  5.4902e-02,\n",
            "        -3.4854e-02,  4.0738e-02,  6.1360e-02, -5.8330e-02, -1.7458e-02,\n",
            "         2.9681e-02,  1.0029e-01, -6.3505e-02, -4.5311e-02, -3.6449e-03,\n",
            "         6.5305e-02, -5.0129e-03, -5.2382e-02,  8.1859e-02, -9.5105e-02,\n",
            "         2.0243e-02,  4.9093e-02, -4.4436e-02,  1.0640e-01,  6.4271e-02,\n",
            "         3.2903e-03, -1.6240e-02,  1.3717e-01,  2.5581e-02,  8.8495e-03,\n",
            "        -3.6468e-02, -1.1885e-01, -9.2884e-03,  3.0671e-02, -6.6120e-02,\n",
            "        -4.0081e-02,  2.2527e-02,  9.8551e-03, -3.5805e-02,  8.1459e-03,\n",
            "         2.0638e-02,  1.3284e-02,  2.3009e-02, -1.0286e-02,  2.2384e-03,\n",
            "        -1.1253e-02,  7.2492e-02,  3.2787e-03,  6.3243e-02, -2.8947e-03,\n",
            "        -1.1667e-01, -7.4549e-02,  4.4358e-02, -8.2620e-02,  1.1166e-01,\n",
            "         1.5125e-01, -1.9300e-02,  1.1386e-02, -9.1702e-02,  3.2448e-02,\n",
            "         6.2955e-02, -2.6065e-02,  3.1307e-02,  7.4683e-03,  6.2372e-03,\n",
            "         1.9449e-03,  1.8325e-03, -2.2728e-02, -4.1205e-02, -6.1542e-02,\n",
            "        -8.7637e-02,  8.5796e-02, -7.4477e-02,  3.4366e-03, -7.6431e-02,\n",
            "         5.0030e-02,  1.0688e-01,  2.4545e-02,  6.1574e-02, -3.2504e-02,\n",
            "        -4.5677e-02,  4.6570e-02, -8.7029e-02, -3.1193e-02, -9.9602e-02,\n",
            "         4.9286e-02,  7.3729e-02, -2.3216e-02,  6.5428e-02, -5.4428e-02,\n",
            "        -9.9403e-02, -2.8248e-02, -4.4417e-02, -2.5457e-02, -3.6502e-04,\n",
            "        -1.3495e-01,  2.6552e-03,  5.7537e-02,  7.0993e-02, -5.3791e-02,\n",
            "         1.6226e-02, -1.3650e-02, -2.6462e-02,  3.0804e-02, -6.4026e-02,\n",
            "        -3.6695e-02,  5.0773e-02, -2.1446e-02, -5.4519e-02,  7.4342e-02,\n",
            "        -6.0322e-02,  1.5916e-01, -3.2845e-02,  4.3921e-02, -7.7010e-02,\n",
            "         7.8180e-02, -9.2032e-02, -3.7716e-02,  2.4632e-02,  2.3931e-02,\n",
            "        -2.9680e-02, -5.9325e-02, -3.6867e-02,  1.6685e-02,  8.0139e-02,\n",
            "         1.1627e-01, -9.6804e-02, -2.5030e-02,  7.1939e-02,  3.7826e-02,\n",
            "        -2.3116e-02,  1.9377e-02,  5.5771e-02,  2.8299e-02,  8.8354e-02,\n",
            "         8.9429e-02,  3.9274e-03, -1.2072e-02,  3.5145e-02,  5.1790e-02,\n",
            "         6.6553e-02,  1.0693e-01,  6.7052e-02, -1.2639e-02, -2.5684e-02,\n",
            "         4.4407e-02,  4.1384e-02, -7.2556e-02,  3.3497e-02,  6.3145e-02,\n",
            "        -3.9140e-02, -8.8639e-02, -5.9654e-02, -5.1677e-02,  9.2961e-02,\n",
            "        -7.8955e-02,  2.8344e-02, -7.8616e-02, -7.9141e-02,  7.2670e-02,\n",
            "         6.2441e-02,  3.9241e-02, -6.3559e-02,  1.3629e-01,  4.8304e-03,\n",
            "        -3.1968e-02,  3.0125e-02, -1.4570e-01, -1.2917e-01,  1.0018e-01,\n",
            "        -5.1024e-02, -1.1244e-01,  3.9312e-02,  5.5495e-02,  1.1402e-02,\n",
            "         3.2801e-02,  4.1715e-02,  1.1523e-01, -8.1881e-02,  4.6371e-02,\n",
            "        -4.5215e-02,  2.7157e-02, -3.8452e-02,  4.0429e-02, -6.5353e-03,\n",
            "        -8.3145e-02,  3.1532e-01,  1.8617e-02,  6.9544e-02, -1.0359e-01,\n",
            "         7.5077e-02, -8.4081e-02,  1.1780e-02, -2.1629e-02,  7.8984e-02,\n",
            "        -2.1615e-02,  3.3484e-02, -4.5692e-02,  1.1946e-01,  8.2880e-02,\n",
            "         3.8252e-02, -6.5423e-02, -4.4783e-02, -7.7759e-02, -4.1360e-02,\n",
            "         4.7463e-02, -1.4633e-02,  2.5368e-02,  2.8012e-02, -9.1503e-03,\n",
            "        -1.0555e-02, -2.7937e-02, -9.2401e-02, -5.3262e-02, -1.4409e-02,\n",
            "        -4.3509e-02, -2.4556e-02,  1.2852e-02,  1.8755e-03,  4.5048e-02,\n",
            "        -5.4014e-02, -6.4197e-02,  1.0071e-01, -1.6880e-02,  1.5601e-02,\n",
            "         7.8173e-03,  8.3860e-02, -6.8275e-02, -6.2824e-02,  4.6466e-02,\n",
            "         5.3904e-02, -9.6926e-02, -2.8655e-02, -4.3569e-03,  1.9911e-02,\n",
            "         4.3379e-02, -4.5663e-02, -8.2773e-02,  8.7674e-02, -9.5458e-02,\n",
            "         7.6618e-03, -2.3161e-02, -8.0790e-02, -4.8705e-02, -3.0918e-02,\n",
            "         7.7278e-02, -1.4070e-02, -7.8230e-02, -2.5738e-02,  1.5154e-02,\n",
            "         7.0194e-02,  1.0977e-02, -1.2214e-02, -5.7059e-03,  1.5009e-02,\n",
            "         5.9599e-02, -7.2242e-04, -2.1348e-02,  5.1361e-02, -8.8413e-02,\n",
            "         1.5357e-02, -4.0958e-02, -8.9058e-02,  1.8001e-01,  5.2453e-02,\n",
            "        -3.7908e-03, -8.5678e-02,  2.8326e-02, -6.7222e-02,  5.8084e-02,\n",
            "         5.0886e-02,  1.2680e-02, -5.5694e-02, -9.3514e-02,  8.7704e-02,\n",
            "         6.1907e-02,  5.1292e-02, -7.7971e-02,  5.4937e-02, -1.7275e-02,\n",
            "        -1.7623e-02,  1.8238e-02,  6.3442e-02,  3.0757e-02, -7.5013e-02,\n",
            "        -1.2891e-02, -8.2182e-02,  2.1459e-02, -1.2069e-02,  3.3717e-02,\n",
            "        -7.1260e-02,  1.6758e-02,  5.9440e-02, -1.5073e-03,  3.0534e-02,\n",
            "         4.8961e-02, -2.3093e-02,  3.9580e-02,  6.0425e-03,  2.9233e-02,\n",
            "         3.9208e-02,  8.6872e-02, -4.4282e-02, -5.1735e-02,  6.7806e-02,\n",
            "         4.8966e-02, -6.8848e-02, -7.4377e-02, -6.8395e-02, -5.9334e-02,\n",
            "        -5.7846e-02, -1.3042e-02,  3.4109e-02,  1.7341e-02, -5.3662e-02,\n",
            "        -1.6383e-02,  8.6317e-02, -1.0980e-02, -2.0100e-02, -1.1505e-01,\n",
            "        -1.2055e-01,  8.7802e-02,  6.4190e-02,  5.1485e-03,  2.9531e-02,\n",
            "        -5.2926e-03, -7.7136e-02, -1.3413e-01, -5.5593e-02, -4.9061e-02,\n",
            "         9.5413e-02,  1.6256e-02, -4.0353e-02, -8.5060e-03,  9.3247e-02,\n",
            "         6.8997e-02,  1.0668e-01, -2.0099e-02, -1.1004e-01, -4.1560e-02,\n",
            "        -1.2688e-02, -3.4829e-02,  7.2097e-02,  5.8836e-02, -1.5844e-02,\n",
            "        -4.5751e-02,  5.0879e-02, -8.2467e-02, -4.4536e-02,  3.2064e-02,\n",
            "        -2.9572e-02,  2.4847e-02, -2.3878e-02,  2.3243e-02, -2.8683e-02,\n",
            "        -4.9886e-02, -1.4078e-02,  5.6217e-02,  5.6717e-02, -3.6553e-02,\n",
            "         6.8757e-02,  1.0462e-02,  2.9738e-03,  2.6244e-02,  8.1162e-03,\n",
            "        -5.2051e-02, -8.6070e-02,  1.7543e-02, -8.0250e-02, -4.2230e-02,\n",
            "         3.7361e-02,  6.6993e-02, -6.0454e-02,  3.6858e-02, -6.8713e-02,\n",
            "         2.2750e-03, -1.9572e-02,  6.7633e-02,  7.0140e-03, -2.0533e-02,\n",
            "         5.4271e-02,  1.3548e-01,  5.4032e-02,  5.9331e-02, -1.1282e-01,\n",
            "         1.1403e-01,  4.5217e-02,  6.4966e-02,  3.6125e-02, -4.1154e-03],\n",
            "       requires_grad=True)\n",
            "torch.Size([585])\n",
            "None\n",
            "48\n",
            "stark\n",
            "85\n",
            "where\n",
            "132\n",
            "Maria\n",
            "57\n",
            "people\n",
            "145\n",
            "health\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5V1uRZ5MFVWM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "\n",
        ">** 1. Gensim**\n",
        "\n",
        ">> 1) Overall :https://towardsdatascience.com/word-embedding-with-word2vec-and-fasttext-a209c1d3e12c \n",
        "\n",
        ">> 2) gensim.word2vec usuage  :https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial\n",
        "\n",
        ">> 3) Korean Ted Scripts :https://www.ted.com/talks?sort=newest&language=ko\n",
        "\n",
        ">>4) Install Korean On Matplotlib :https://colab.research.google.com/github/nicewook/datascience_exercise/blob/master/korean_font_on_matplotlib.ipynb\n",
        "\n",
        "\n",
        ">** 2. Continuous Bag of Words/Skipgrams**\n",
        "\n",
        ">> 1) Overall :https://srijithr.gitlab.io/post/word2vec/\n",
        "\n",
        ">** 3. In Datail**\n",
        "\n",
        "> >1) Pytorch Library :https://github.com/pytorch/pytorch\n",
        "\n",
        ">> 2) Pytorch Tutorial :https://tutorials.pytorch.kr/beginner/nlp/word_embeddings_tutorial.html"
      ]
    }
  ]
}